{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7b13e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf4llm\n",
    "import pymupdf\n",
    "import PIL.Image\n",
    "import io\n",
    "\n",
    "\n",
    "pdf_path = '/Users/ngocduy/Documents/PAPERS/cs_DB/Cognitive Database_ A Step towards Endowing Relational Databases with Artificial Intelligence Capabilities.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43e6a709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metadata': {'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref package', 'producer': 'pdfTeX-1.40.17', 'creationDate': 'D:20171221013320Z', 'modDate': 'D:20171221013320Z', 'trapped': '', 'encryption': None, 'file_path': '/Users/ngocduy/Documents/PAPERS/cs_DB/Cognitive Database_ A Step towards Endowing Relational Databases with Artificial Intelligence Capabilities.pdf', 'page_count': 14, 'page': 1}, 'toc_items': [[1, '1 Introduction', 1]], 'tables': [], 'images': [], 'graphics': [], 'text': '## **Cognitive Database: A Step towards Endowing Relational** **Databases with Artificial Intelligence Capabilities**\\n\\n\\n\\n\\n_†_\\nOded Shmueli\\n\\nCS Department, Technion\\nHaifa 32000, Israel\\noshmu@cs.technion.ac.il\\n\\n\\n\\nRajesh Bordawekar\\nIBM T. J. Watson Research\\nCenter\\nYorktown Heights, NY 10598\\nbordaw@us.ibm.com\\n\\n\\n**ABSTRACT**\\n\\n\\n\\n_∗_\\nBortik Bandyopadhyay\\n\\nThe Ohio State University\\nColumbus, OH 43210\\nbandyopadhyay.14\\n@osu.edu\\n\\n\\n\\nWe propose Cognitive Databases, an approach for transparently enabling Artificial Intelligence (AI) capabilities in\\nrelational databases. A novel aspect of our design is to first\\nview the structured data source as meaningful unstructured\\ntext, and then use the text to build an unsupervised neural\\nnetwork model using a Natural Language Processing (NLP)\\ntechnique called word embedding. This model captures the\\nhidden inter-/intra-column relationships between database\\ntokens of different types. For each database token, the model\\nincludes a vector that encodes contextual semantic relation\\nships. We seamlessly integrate the word embedding model\\ninto existing SQL query infrastructure and use it to enable\\na new class of SQL-based analytics queries called cognitive\\nintelligence (CI) queries. CI queries use the model vectors to\\nenable complex queries such as semantic matching, inductive\\nreasoning queries such as analogies, predictive queries using\\nentities not present in a database, and, more generally, using\\nknowledge from external sources. We demonstrate unique\\ncapabilities of Cognitive Databases using an Apache Spark\\nbased prototype to execute inductive reasoning CI queries\\nover a multi-modal database containing text and images.\\nWe believe our first-of-a-kind system exemplifies using AI\\nfunctionality to endow relational databases with capabilities that were previously very hard to realize in practice.\\n\\n\\n**1.** **INTRODUCTION**\\n\\n\\nArtificial Intelligence: Systems that perform actions that, if performed by humans, would be\\nconsidered intelligent –Marvin Minsky\\n\\n\\nWikipedia defines _cognition_ as the mental action or process of acquiring knowledge and understanding through thought,\\n\\n_∗_ Work done while the author was visiting the IBM Watson\\nResearch Center.\\n\\n_†_\\nWork done while the author was visiting the IBM Watson\\nResearch Center.\\n\\n\\n1\\n\\n\\n\\nexperience, and the senses. In broad terms, cognition refers\\nto the process of building knowledge capabilities using innate resources (i.e. intelligence), enriching it with external inputs such as experiences or interactions, and applying\\nthe knowledge to solve problems which feeds back towards\\nknowledge building. While these definitions are more relevant to animate objects, they can be also applicable to\\nscenarios in which inanimate entities simulate cognitive pro\\ncesses.\\nWe focus on a particular cognitive process of _reading com-_\\n_prehension of text via contexts_ and apply it to _relational_\\n_databases_ . In the relational model, some relationships between database values and entities are defined at the schema\\nlevel: data types, keys, and functional (and other) dependencies. Relationships at the instance level (i.e. actual data\\ntables) are left to be explored by queries. In a strong sense,\\nthe actual semantics of the data mostly lies in users’ minds\\nand is expressed via queries. We take a significant diversion\\nfrom this point of view. We postulate that there is significant _latent_ knowledge in a database instance irrespective of\\nquerying. To capture this latent knowledge we propose to\\nuse Artificial Intelligence (AI) techniques that take advantage of contexts.\\nSpecifically, in the relational database model, the main\\nsources of latent information include the structure of database\\n(e.g., column names in a relation) as well as the types of associated data values that include unstructured natural language text, strings, numerical values, images, SQL Dates\\netc. Together, these factors lead to inter- and intra-column\\n_semantic_ relationships. Current systems have limited support to exploit this information, namely via SQL and extensions such as text extenders [14] or RDF-based ontologies [38]. However, SQL queries rely mainly on value-based\\npredicates to detect patterns. In addition, the relational\\ndata model ignores many inter- or intra-column relationships. Thus, traditional SQL queries lack a holistic view of\\nthe underlying relations and thus are unable to extract and\\nexploit semantic relationships that are collectively generated\\nby the various _entities_ in a database relation.\\nA few examples may serve to clarify what we mean by\\nlatent knowledge. The first example considers a Human Resources (HR) database. This database contains relations\\nwith information about employees, their work history, pay\\ngrade, addresses, family members and more. Lately there\\nhave been some issues with an employee, John Dolittle. As\\na HR professional, you are interested in names of employees\\nwho know John well. Sure, you can get on the phone (or any\\n\\n\\n', 'words': []}\n",
      "\n",
      "{'metadata': {'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref package', 'producer': 'pdfTeX-1.40.17', 'creationDate': 'D:20171221013320Z', 'modDate': 'D:20171221013320Z', 'trapped': '', 'encryption': None, 'file_path': '/Users/ngocduy/Documents/PAPERS/cs_DB/Cognitive Database_ A Step towards Endowing Relational Databases with Artificial Intelligence Capabilities.pdf', 'page_count': 14, 'page': 2}, 'toc_items': [[1, '2 Designing a Cognitive Database', 2]], 'tables': [], 'images': [], 'graphics': [], 'text': 'other media) and start making calls, collecting information\\nuntil you have a few names of people with whom you would\\nlike to consult. Much of the information you will obtain is\\nalready _hidden_ in the _legacy_ database, but is diffused and\\nhard to get at. This may include people who worked with\\nJohn, managed him, complimented him, complained about\\nhim, provided technical services to him, were members of\\na small team with him and so on. Wouldn’t it be nice if\\nyou could write a SQL query that would use this hidden\\nknowledge and essentially ask _provide the names of the 10_\\n_employees most related to John Dolittle_ .\\nIn the previous example, we relied on the content of the\\ndatabase in isolation. The next example involves entities\\nexternal to the database. Suppose you have database of active vacations, featuring diving, hiking, skiing, desert driving and more. You are a bit worried as to which vacation package is the most dangerous one. Naturally, the official descriptions in the database will not always provide\\nthe information. It is likely that the words _accident_, _dan-_\\n_ger_, _wounded_, and _death_ will not even be present in the\\ndatabase. These words are present in other data sources,\\nfrom Wikipedia to news articles. Suppose you have access\\nto such external sources. Wouldn’t it be nice if you could\\nutilize these external sources and pose a SQL query expressing _which are the most dangerous vacation packages_ . In this\\nexample, as well as the previous ones, you may want also\\nto have a degree of certainty associated with each potential\\n\\nanswer.\\nIt is worth pointing out what distinguishes the level of\\nintelligence we are looking for from known extensions to relational systems. In current systems one needs to pose a\\nquery based on some knowledge of the relational schema.\\nThe query may be _assisted_ by text-aware features such as\\nDB2 Text Extender [14], WordNet or using RDF-based ontologies [38]. These may be used to identify synonyms and\\nrelated terms and relax the query by allowing it to explore more possibilities than those explicitly specified by the\\nuser [11]. Of course, such relaxation may result in obtaining a larger result set. But, all these useful features assume\\nthat the user knows how to specify a backbone query. The\\nexample problems we listed above are such that formulating\\nan effective SQL query is a daunting task. In fact, these\\nexamples resemble research projects rather than standard\\nqueries. One can also allow the user to specify the query\\nin natural language [37], but this pushes the problem of expressing a query to an automated tool; again, it is unclear\\nhow a tool will approach these problem if the tool’s writer\\ndoes not have a ready recipe. This highlights the need of a\\nnew set of tools to enable far richer querying.\\nIn this paper, we explore the potential of using Natural\\nLanguage Processing (NLP) approaches to endow databases\\nwith query expression capabilities that were very hard, or\\nperhaps impossible, to realize in practice, and at a reasonable cost in terms of storage overhead as well as processing\\ntime. The unique aspect of our proposal is to first represent\\nthe data and optionally, schema, of a (structured) relational\\ndatabase as an unstructured text document and then use a\\nNLP technique, _Vector Space Models (VSM)_ [55], to extract\\nlatent semantic relationships via associations in the generated text. The trained VSM model represents the semantic\\nmeaning of the words as vectors and enables operations on\\nthese vectors to mimic cognitive operations on natural language words. As these words represent relational entities\\n\\n\\n\\nand values, the VSM model, in fact, captures intra-/intercolumn relationships in the relational database. We then integrate the VSM model into an existing standard SQL query\\nprocessing system and expose the novel vector-based cognitive operations via a new class of SQL analytics queries,\\ncalled _Cognitive Intelligence (CI)_ queries [8]. We believe\\nthis is one of the first examples of AI _transperently aug-_\\n_menting_ a relational database system. Clearly, this is only\\none of the many possible ways of integrating AI capabilities in database systems, e.g., for enhancing their querying\\ncapabilities or improving their operational capabilities [50,\\n59, 37]. While our current focus is on enhancing relational\\ndatabases, we believe this approach can be applied to other\\ndatabase domains such as XML/RDF or JSON databases,\\ndocument databases, graph databases, and key-value stores.\\nWe are currently developing an Apache Spark-based prototype to implement our vision of an AI-enhanced cognitive\\nrelational database. The rest of the paper provides more details on the design and implementation of such a system. In\\nSection 2, we introduce the vector space modeling process\\nand detail the execution flow of the system we envisage.\\nIn Section 3, we provide specifics of the data preparation\\nand building a specialized vector space model. In Section 4\\nwe discuss three significant classes of CI queries: Similarity\\nQueries, Inductive Reasoning Queries and Cognitive OLAP\\nQueries; we also present cognitive extensions to the Relational Data Model. We also describe the design of cognitive\\nUser Defined Functions (UDFs). Section 5 describes a practical scenario which demonstrates unique aspects of a cognitive database system: ability to invoke inductive reasoning (e.g., analogies, semantic clustering, etc.) queries over\\nmulti-modal data (e.g., images and text). We also discuss\\nCI query performance issues, with focus on an important\\nbuilding block: Nearest-Neighbor Computations. Related\\nwork is discussed in Section 6 and we conclude by outlining\\nextensions, future work, and success criteria in Section 7.\\n\\n\\n**2.** **DESIGNING A COGNITIVE DATABASE**\\n\\nOur goal is to build a cognitive relational database system\\nthat not only extracts latent semantic information, but can\\nalso enrich it by using external input (e.g., external knowledge bases, new data being inserted, or types of invoked\\nqueries) and use it _transparently_ to enhance its query capabilities. To achieve these goals, we rely on the VSM approach that infers word meanings using the distributional\\nhypothesis, which states that words in a neighborhood (or\\ncontext) contribute to each other’s meanings [24, 26]. Specifically, we use a _predictive_ [4] implementation of the VSM\\napproach, commonly referred to as _word embedding_, which\\nassumes a probabilistic language model to capture relationships between neighborhood words [5]. The word embedding\\napproach fixes a _d_ -dimensional vector space and associates\\na vector of continuous-valued real numbers to a word to\\nencode the meaning of that word. Thus, for a given text\\ncorpus, the meaning of a word reflects collective contributions of neighborhood words for different appearances of the\\nword in the corpus. Two words are closely related or have\\nsimilar meaning if they appear often within close proximity\\nof the same, or similar meaning, words. If two words have\\nsimilar meaning, their meaning vectors point in very similar\\ndirections, i.e., the cosine similarity between their vectors is\\nhigh (vector similarity is measured as a cosine of the angle\\n\\n\\n\\n2\\n\\n\\n', 'words': []}\n",
      "\n",
      "{'metadata': {'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref package', 'producer': 'pdfTeX-1.40.17', 'creationDate': 'D:20171221013320Z', 'modDate': 'D:20171221013320Z', 'trapped': '', 'encryption': None, 'file_path': '/Users/ngocduy/Documents/PAPERS/cs_DB/Cognitive Database_ A Step towards Endowing Relational Databases with Artificial Intelligence Capabilities.pdf', 'page_count': 14, 'page': 3}, 'toc_items': [[1, '3 Building the Semantic Model', 3]], 'tables': [{'bbox': (54.112998962402344, 499.15899658203125, 293.06298828125, 559.9089965820312), 'rows': 5, 'columns': 7}, {'bbox': (317.12701416015625, 54.56300354003906, 556.0770263671875, 115.31300354003906), 'rows': 5, 'columns': 7}, {'bbox': (336.42449951171875, 264.3310241699219, 537.0772705078125, 340.7996826171875), 'rows': 3, 'columns': 4}, {'bbox': (351.7056884765625, 267.8699951171875, 409.16497802734375, 296.73187255859375), 'rows': 3, 'columns': 3}], 'images': [], 'graphics': [], 'text': 'between two vectors and can vary from 1.0 to -1.0). One surprising application of word-embedding vectors is their usage\\nin solving inductive reasoning problems such as computing\\nanalogies by using vector algebra calculations [58, 54, 35].\\nOver a past few years, a number of methods have been\\ndeveloped to implement the word embedding. Recently, an\\n_unsupervised_ neural network based approach,\\nWord2Vec [42, 45], has gained popularity due to its performance and ability to capture syntactic as well semantic\\nproperties of words. We use Word2Vec as it is easy to adapt,\\ncan be trained incrementally, and can be used for building\\nmodels from both structured and unstructured data sources\\n(alternatively, we could use approaches such as GloVe [51]).\\nIn the database context, vectors may be produced by either learning on text transformed and extracted from the\\ndatabase itself and/or using external text sources. For learning from a database, a natural way of generating vectors is\\nto apply the word embedding method to a string of tokens\\ngenerated from the database: each row (tuple) would correspond to a sentence and a relation would correspond to a\\ndocument. Thus, vectors enable a _dual view_ of the data: relational and meaningful text. To illustrate this process, consider Figures 1 and 2 that present a simple customer sales\\ntable. Figure 1 shows an English sentence-like representation of the fourth row in the table (note that the numeric\\nvalue `25.00` is represented by the string `cluster` ~~`1`~~ `0` . We\\ndiscuss the reasons in the next section.). Using the scope of\\nthe generated sentence as the context, the word embedding\\napproach infers latent semantic information in terms of token associations and co-occurrences and encode it in vectors.\\n\\nThus, the vectors capture first inter- and intra-column relationships within a row (sentence) and then aggregate these\\nrelationships across the relation (document) to compute the\\n_collective semantic_ relationships. At the end of training,\\neach unique token in the database would be associated with\\na _d_ -dimensional meaning vector, which can be then used to\\nquery the source database. As a simple example, the relational entity `custD` is _semantically_ similar to `custB` due\\nto many common semantic contributors (e.g., `Merchant` ~~`B`~~,\\n`Stationery`, and `Crayons` ). Equivalently, `custA` is similar\\nto `custC` due to similar reasons.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n|custID|Date|Merchant|Address|Category|Items|Amount|\\n|---|---|---|---|---|---|---|\\n|**custA**|**9/16/17**|Merchant_A|**NY**|Fresh Produce|Bananas, Apples|**200.50**|\\n|**custB**|**10/16/17**|Merchant_B|**NJ**|Stationery|Crayons, Pens, Notebooks|**60.80**|\\n|**custC**|**10/16/17**|Merchant_A|**NJ**|Fresh Produce|Bananas, Oranges|**80.10**|\\n|**custD**|**9/16/17**|Merchant_B|**NY**|Stationery|Crayons, Folders|**25.00**|\\n\\n\\n\\n**custD** **9/16/17** **NY** **cluster_10**\\n\\n\\n**Figure 2: Example of customer analytics with a dif-**\\n**ferent relational view**\\n\\n\\nThis examples illustrates a key design feature of our cognitive database: the neighborhood context used for building\\nthe word embedding model is determined by the relational\\nview being used. Hence, _the inferred semantic meaning of_\\n_the relational entities reflect the collective relationships de-_\\n_fined by the associated relational view._\\n\\n\\n\\n\\n\\n\\n\\n\\n|Col1|arned|Col3|\\n|---|---|---|\\n||||\\n||||\\n|External Tex|External Tex|t sources|\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n|Vector Learned Vectors External<br>Domain Learned Vectors|Col2|Col3|UDFs<br>CI Queries Relations|\\n|---|---|---|---|\\n|Text<br>Domain<br>External Text sources<br>Tokenized Relations|Text<br>Domain<br>External Text sources<br>Tokenized Relations|||\\n|Relational<br>Domain<br>Relational<br>Tables<br>Relational<br>System Tables||||\\n\\n\\n\\n(1) Optional Training Phase\\n\\n\\n\\n(2) Vector Storage Phase (3) Query Execution Phase\\n\\n\\n\\n\\n\\n\\n\\n\\n|custID|Date|Merchant|Address|Category|Items|Amount|\\n|---|---|---|---|---|---|---|\\n|custA|9/16/17|Merchant_A|NY|Fresh Produce|Bananas, Apples|200.50|\\n|custB|10/16/17|Merchant_B|NJ|Stationery|Crayons, Pens, Notebooks|60.80|\\n|custC|10/16/17|Merchant_A|NJ|Fresh Produce|Bananas, Oranges|80.10|\\n|custD|9/16/17|Merchant_B|NY|Stationery|Crayons, Folders|25.00|\\n\\n\\n\\ncustD 9/16/17 Merchant_B NY Stationery Crayons Folders cluster_10\\n\\n\\n**Figure 1: Example of customer analytics**\\n\\n\\n\\nWe may use a relational view of a table, rather than the\\noriginal table, to generate text representing the database\\ncontent. This may be useful for a supporting a particular class of applications. Consider a scenario in which\\na view of the table is defined (Figure 2), the view only\\nprojects data from the bold columns ( `Cust`, `Date`, `Address`\\nand `Amount` ). In this case, the generated sentence-like representation would be different than the first case. Hence, it\\nwill generate a different word embedding model.\\n\\n\\n\\n**Figure 3: End-to-end execution flow of a cognitive**\\n**relational database**\\n\\n\\nThe cognitive relational database has been designed as an\\n_extension_ to the underlying relational database, and thus\\nsupports all existing relational features. The cognitive relational database supports a new class of business intelligence\\n(BI) queries called _Cognitive Intelligence_ (CI) queries. The\\nCI queries extract information from a relational database\\nbased, in part, on the contextual semantic relationships among\\ndatabase entities, encoded as meaning vectors. Figure 3\\npresents key phases in the end-to-end execution flow of a cognitive relational database system. The first, optional, phase\\ninvolves (1) Generating token sequences from the database\\ntables ( _textification_ ), and then applying a word embedding\\nmodel training method on the unstructured text corpus created from these token sequences. Following model training,\\nthe resultant vectors are stored in a relational system table (phase 2). At runtime, the SQL query execution engine\\nuses various user-defined functions (UDFs) that fetch the\\ntrained vectors from the system table as needed and answer\\nCI queries (phase 3). The CI queries take relations as input and return a relation as output. CI queries _augment_\\nthe capabilities of the traditional relational BI queries and\\ncan be used in conjuction with existing SQL operators (e.g.,\\nOLAP [22]).\\n\\n\\n**3.** **BUILDING THE SEMANTIC MODEL**\\n\\n\\nThe key to artificial intelligence has always been\\nthe representation. –Jeff Hawkins\\n\\n\\nIn this section, we discuss how we train a word embedding\\nmodel using data from a relational database. Our training\\n\\n\\n\\n3\\n\\n\\n', 'words': []}\n",
      "\n",
      "{'metadata': {'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref package', 'producer': 'pdfTeX-1.40.17', 'creationDate': 'D:20171221013320Z', 'modDate': 'D:20171221013320Z', 'trapped': '', 'encryption': None, 'file_path': '/Users/ngocduy/Documents/PAPERS/cs_DB/Cognitive Database_ A Step towards Endowing Relational Databases with Artificial Intelligence Capabilities.pdf', 'page_count': 14, 'page': 4}, 'toc_items': [[2, '3.1 Data Preparation', 4], [2, '3.2 Model Training', 4]], 'tables': [], 'images': [], 'graphics': [], 'text': 'approach is characterized by two unique aspects: (1) Using\\n_unstructured text_ representation of the structured relational\\ndata as input to the training process (i.e. irrespective of the\\nassociated SQL types, all entries from a relational database\\nare converted to text tokens representing them), and (2) Using the _unsupervised_ word embedding technique to generate\\nmeaning vectors from the input text corpus. Every unique\\ntoken from the input corpus is associated with a meaning\\nvector. We now elaborate on these two aspects.\\n\\n\\n**3.1** **Data Preparation**\\n\\nThe data preparation stage takes a relational table with\\ndifferent SQL types as input and returns an unstructured\\nbut meaningful text corpus consisting of a set of sentences.\\nThis transformation allows us to generate a uniform semantic representation of different SQL types. This process of\\n_textification_ requires two stages: data pre-processing and\\ntext conversion (Figure 4).\\n\\n\\n\\n(A)\\n\\n\\n(B)\\n\\n\\n(C)\\n\\n\\n(D)\\n\\n\\n(E)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n**Figure 4: Multiple stages in creating the word em-**\\n**bedding model**\\n\\n\\nThe textification phase processes each relational row seperately and for each row, converts data of different SQL data\\ntypes to text. In some scenarios, one may want to build a\\nmodel that also captures relational column names. For such\\ncases, the pre-processing stage first processes the column\\nnames before processing the corresponding data.\\nFor SQL variables of `VARCHAR` type, preprocessing involves\\none or more of the following actions: (1) prepend the column\\nattribute string to a SQL variable, (2) creating a single _con-_\\n_cept_ token from a group of `VARCHAR` tokens, e.g., `JPMorgan`\\n`Chase` is represented as `JPMorgan` `Chase`, (3) creating a single\\n_token_ for semantically similar sequences of `VARCHAR` tokens,\\ne.g., two sequences of tokens, `bank of america` and `BANK`\\n`OF AMERICA`, can be represented by a single compound token `BANK` ~~`O`~~ `F` `AMERICA`, and (4) Using an external mapping\\nor domain-specific ontologies to create a common representative token for a group of different input tokens. This approach is useful for enabling _transfer learning_ via reusing\\nthe same training model for a group of related tokens. After\\npre-processing, all input text tokens have uniform representations.\\n\\nIn addition to text tokens, our current implementation\\nsupports numeric values and images (we assume that the\\ndatabase being queried contains a `VARCHAR` column storing\\nlinks to the images). These techniques can be applied to\\nother SQL datatypes such as SQL Date as well. For numeric values, we use three different approaches to generate\\nequivalent text representations: (1) creating a string version of the numerical value, e.g., value `100.0` for the column name `price` can be represented by either `PRICE` ~~`1`~~ `00.0`\\nor `‘‘100.0’’`, (2) User-managed categorization: a user can\\n\\n\\n\\nspecify rules to define ranges for the numeric values and\\nuse them to generate string tokens for the numeric values.\\nFor example, consider values for a column name, `Cocoa`\\n`Contents` . The value `80%`, can be replaced by the string\\ntoken `choc` ~~`d`~~ `ark`, while the value `35%`, can be replaced by\\nthe string token `choc` ~~`m`~~ `ed`, etc., and (3) user-directed clustering: an user can choose values of one or more numerical columns and cluster them using traditional clustering\\nalgorithms such as K-Means. Each numeric value is then\\nreplaced by a string representing the cluster in which that\\nvalue lies (e.g., `cluster` `10` for value `25` in Figure 1).\\nFor image data, we use approaches similar to ones used for\\nnumerical values. The first approach represents an image by\\nits string token, e.g., a string representing the image path or\\na unique identifier. The second approach uses pre-existing\\nclassifers to cluster images into groups and then uses the\\ncluster information as the string representation of the image. For example, one can use a domain-specific deep neural\\nnetwork (DNN) based classifier to cluster input images into\\nclasses [31] and then use the corresponding class information to create the string identifiers for the images. The final\\napproach applies of-the-shelf image to tag generators, e.g.,\\nIBM Watson Visual Recognition System (VRS) [30], to extract image features and uses them as string identifiers for\\nan image. For example, a Lion image can be represented by\\nthe following string features, `Animal`, `Mammal`, `Carnivore`,\\n`BigCat`, `Yellow`, etc.\\nOnce text, numeric values and images are replaced by\\ntheir text representations, a relational table can be viewed as\\nunstructured meaningful text corpus to be used for building\\nan word embedding model. For `Null` values of these types,\\nwe replace them by the string `column` ~~`n`~~ `ame` ~~`N`~~ `ull` . The methods outlined here can be applied to other data types such\\nas SQL `Date` and spatial data types such as lattitude and\\nlongitude.\\n\\n\\n**3.2** **Model Training**\\n\\nWe use an **unsupervised** approach, based on the Word2Vec\\n(W2V) implementation [42], to build the word embedding\\nmodel from the relational database data. Our training approach operates on the unstructured text corpus, organized\\nas a collection of _English-like_ sentences, separated by stop\\nwords (e.g., newline). There is no need of labelling the training data as we use unsupervised training. Another advantage of unsupervised training is that users do not need to\\ndo any feature engineering [20]; features of the training set\\nare extracted automatically by the training process.\\nDuring model training, the classical W2V implementation\\nuses a simplified 3-layer shallow neural network that views\\nthe input text corpus as a sequence of sentences. For each\\nword in a sentence, the W2V code defines a neighborhood\\nwindow to compute the contributions of nearby words. Unlike deep learning based classifiers, the output of W2V is\\na set of vectors of real values of dimension _d_, one for each\\nunique token in the training set (the vector space dimension\\n_d_ is independent of the token vocabulary size). In our scenario, a text token in a training set can represent either text,\\nnumeric, or image data. Thus, the model builds a _joint_ latent representation that integrates information across different _modalities_ using _untyped uniform_ feature (or _meaning_ )\\nvectors.\\nOur training implementation builds on the classical W2V\\nimplementation, but it varies from the classical approach in\\n\\n\\n\\n4\\n\\n\\n', 'words': []}\n",
      "\n",
      "{'metadata': {'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref package', 'producer': 'pdfTeX-1.40.17', 'creationDate': 'D:20171221013320Z', 'modDate': 'D:20171221013320Z', 'trapped': '', 'encryption': None, 'file_path': '/Users/ngocduy/Documents/PAPERS/cs_DB/Cognitive Database_ A Step towards Endowing Relational Databases with Artificial Intelligence Capabilities.pdf', 'page_count': 14, 'page': 5}, 'toc_items': [[1, '4 Building a Cognitive Database System', 5]], 'tables': [{'bbox': (328.1468811035156, 60.77033233642578, 542.69970703125, 138.78953552246094), 'rows': 3, 'columns': 8}, {'bbox': (347.6517028808594, 99.7799301147461, 532.947265625, 122.53553771972656), 'rows': 2, 'columns': 7}], 'images': [], 'graphics': [], 'text': '**empl Relation**\\n\\n\\n\\na number of ways (Figure 4):\\n\\n\\n_•_ A sentence generated from a relational row is generally\\nnot in any natural language such as English. [1] Therefore, W2V’s assumption that the influence of any word\\non a nearby word decreases as the word distances increases, is not applicable. In our implementation, every token in the training set has the same influence on\\nthe nearby tokens; i.e. we view the generated sentence\\nas a bag of words, rather than an ordered sequence.\\n\\n\\n_•_ Another consequence is that unlike an English sentence, the last word is equally related to the first word\\nas to its other neighbors. To enable such relationships, we use a circular neighborhood window that\\nwraps around a sentence (i.e. for the last word, the\\nfirst word can be viewed as its immediate neighbor).\\n\\n\\n_•_ For relational data, we provide special consideration\\nto primary keys. First, the classical W2V discards\\nless frequent words from computations. In our implementation, every token, irrespective of its frequency,\\nis assigned a vector. Second, irrespective of the distance, a primary key is considered a neighbor of every\\nother word in a sentence and included in the neighborhood window for each word. Also, the neighborhood\\nextends via foreign key occurrences of a key value to\\nthe row in which that value is key.\\n\\n\\n_•_ In some cases, one may want to build a model in which\\nvalues of particular columns are given higher weightage for their contributions towards meanings of neighborhood words. Our implementation enables users to\\nspecify different weights (or attention [3]) for different\\ncolumns during model training (in this scenario, one\\nneeds to use a training set in which column names are\\nembedded).\\n\\n\\n_•_ Finally, our implementation is designed to enable _in-_\\n_cremental_ training, i.e. the training system takes as\\ninput a pre-trained model and a new set of generated\\nsentences, and returns an updated model. This capability is critical as a database can be updated regularly\\nand one can not rebuild the model from scratch every\\ntime. The pre-trained model can be built from the\\ndatabase being queried, or from an external source.\\nSuch sources may be publicly available general sources\\n(e.g., Wikipedia), text from a specific domain (e.g.,\\nfrom the FDA regarding medical drugs), text textified from other databases or text formed from a different subset of tables of the same database. The use of\\npre-trained models is an example of _transfer_ learning,\\nwhere a model trained on an external knowledge base\\ncan be used either for querying purposes or as a basis\\nof a new model [20].\\n\\n\\nIn practice, enterprise database systems, as well as data\\nwarehouses, are built using many inter-related database tables. Forming a training corpus from multiple tables is nontrivial. There are numerous options, including:\\n\\n\\n_•_ Build separate models (i.e. a set of word vectors), each\\nbased on an individual, informative, table.\\n\\n\\n1 Currently, we assume that database tokens are specified\\nusing the English language.\\n\\n\\n\\n**(Primary Key)**\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n|empNum|firstName|lastName|salary|dept|jobDescr|eval|address|\\n|---|---|---|---|---|---|---|---|\\n|259|John|Smith|95|Multimedia|manager<br>multimedia<br>entertainment|good people skills<br>not punctual<br>need improvement|119|\\n|**(Primary Key)**<br>**address Relation**<br>**id**<br>**stNum**<br>**street**<br>**city**<br>**state**<br>**remarks**<br>119<br>100<br>10th<br>Newark<br>NJ<br>alternate 19 Chatsworth Ave Larchmont NY<br>**zip**<br>07105<br>**(Foreign Ke**|**(Primary Key)**<br>**address Relation**<br>**id**<br>**stNum**<br>**street**<br>**city**<br>**state**<br>**remarks**<br>119<br>100<br>10th<br>Newark<br>NJ<br>alternate 19 Chatsworth Ave Larchmont NY<br>**zip**<br>07105<br>**(Foreign Ke**|**(Primary Key)**<br>**address Relation**<br>**id**<br>**stNum**<br>**street**<br>**city**<br>**state**<br>**remarks**<br>119<br>100<br>10th<br>Newark<br>NJ<br>alternate 19 Chatsworth Ave Larchmont NY<br>**zip**<br>07105<br>**(Foreign Ke**|**(Primary Key)**<br>**address Relation**<br>**id**<br>**stNum**<br>**street**<br>**city**<br>**state**<br>**remarks**<br>119<br>100<br>10th<br>Newark<br>NJ<br>alternate 19 Chatsworth Ave Larchmont NY<br>**zip**<br>07105<br>**(Foreign Ke**|**(Primary Key)**<br>**address Relation**<br>**id**<br>**stNum**<br>**street**<br>**city**<br>**state**<br>**remarks**<br>119<br>100<br>10th<br>Newark<br>NJ<br>alternate 19 Chatsworth Ave Larchmont NY<br>**zip**<br>07105<br>**(Foreign Ke**|**(Primary Key)**<br>**address Relation**<br>**id**<br>**stNum**<br>**street**<br>**city**<br>**state**<br>**remarks**<br>119<br>100<br>10th<br>Newark<br>NJ<br>alternate 19 Chatsworth Ave Larchmont NY<br>**zip**<br>07105<br>**(Foreign Ke**|**(Primary Key)**<br>**address Relation**<br>**id**<br>**stNum**<br>**street**<br>**city**<br>**state**<br>**remarks**<br>119<br>100<br>10th<br>Newark<br>NJ<br>alternate 19 Chatsworth Ave Larchmont NY<br>**zip**<br>07105<br>**(Foreign Ke**|**(Primary Key)**<br>**address Relation**<br>**id**<br>**stNum**<br>**street**<br>**city**<br>**state**<br>**remarks**<br>119<br>100<br>10th<br>Newark<br>NJ<br>alternate 19 Chatsworth Ave Larchmont NY<br>**zip**<br>07105<br>**(Foreign Ke**|\\n\\n\\n|id|stNum|street|city|state|zip|remarks|\\n|---|---|---|---|---|---|---|\\n|119|100|10th|Newark|NJ|07105|alternate 19 Chatsworth Ave Larchmont NY|\\n\\n\\n259 John Smith 95 Multimedia manager multimedia entertainment good people skills\\nnot punctual need improvement **119 100 10th Newark NJ 07105**\\n**alternate 19 Chatsworth Ave Larchmont NY** ..............................................................\\n\\n\\n**Figure 5: Text view of two tables joined using pri-**\\n**mary and foreign keys**\\n\\n\\n_•_ Build models each based on linked tables where, usually, the linking is based on foreign keys appearing in\\nsay table `A` pointing to tuples into another, say table\\n`B` . When a foreign key is present, during tokenization\\nof table `A`, we can follow the foreign key to a row in\\ntable `B` . We can then tokenize fields of interest in the\\nrow of table `B` and insert the resulting sequences into\\nthe sequence generated for table `A` . Figure 5 presents\\nanother example of a database table, `address`, and a\\nresulting token sequence that utilizes a relationship between the `empl` table and the `address` table; namely\\nthe `address` table provides the addresses for the employees of database table `empl` . Technically, the resulting token sequence is based on foreign key `119` in\\nthe `address` column of the table _emp_ which provides\\na value for key column `id` of the `address` table. The\\nstraight forward way to tokenize with foreign keys is\\nto insert the subsequence generated out of the `B` row\\nimmediately after the one generated for the `A` row as\\ndepicted in Figure 5; another possibility is to intermix\\nthe subsequence from the `B` row within the `A` row sequence following the tokenization of the foreign keys\\nvalues (again, other options may apply).\\n\\n\\n_•_ A collection of tables may be identified and textified\\ninto a collection of texts. These texts may be concatenated to form a single text which may be used in\\ntraining. The tables in this collection should form a\\ncoherent informative subset of the database.\\n\\n\\n_•_ In all the options above, the training text may be augmented with text from external sources.\\n\\n\\n**4.** **BUILDING A COGNITIVE DATABASE**\\n\\n**SYSTEM**\\n\\nCognitive intelligence (CI) queries are standard SQL queries\\nand can be implemented using the existing SQL query execution infrastructure. The distinguishing aspect of cognitive intelligence queries, contextual semantic comparison between relational variables, is implemented using user-defined\\nfunctions (UDFs). These UDFs, termed _cognitive_ UDFs,\\ntake _typed_ relational values as input and compute semantic\\nrelationships between them using _uniformly untyped_ meaning vectors. This enables the relational database system to\\nseamlessly analyze data of different types (e.g., text, numeric\\nvalues, and images) using the same SQL CI query.\\nOur current implementation is built on the Apache Spark\\n2.2.0 infrastructure. Our system follows the cognitive database\\n\\n\\n\\n5\\n\\n\\n', 'words': []}\n",
      "\n",
      "{'metadata': {'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref package', 'producer': 'pdfTeX-1.40.17', 'creationDate': 'D:20171221013320Z', 'modDate': 'D:20171221013320Z', 'trapped': '', 'encryption': None, 'file_path': '/Users/ngocduy/Documents/PAPERS/cs_DB/Cognitive Database_ A Step towards Endowing Relational Databases with Artificial Intelligence Capabilities.pdf', 'page_count': 14, 'page': 6}, 'toc_items': [[2, '4.1 Design of Cognitive UDFs', 6], [2, '4.2 Cognitive Intelligence Queries', 6]], 'tables': [], 'images': [], 'graphics': [], 'text': 'execution flow as presented in Figure 3. The system first\\ninitializes in-memory Spark Dataframes from external data\\nsources (e.g., relational database or CSV files), loads the associated word embedding model into another Spark Dataframe\\n(which can be created offline from either the database being\\nqueried or external knowledge bases such as Wikipedia), and\\nthen invokes CI queries using Spark SQL. The SQL queries\\ninvoke Scala-based cognitive UDFs to enable computations\\non the meaning vectors (we also provide a Python based\\nimplementation).\\n\\n\\n**4.1** **Design of Cognitive UDFs**\\nA cognitive UDF takes as input either relational query\\nvariables or constant tokens, and returns a numeric similarity value that measures the semantic relationships between\\nthe input parameters. A user can then control the result\\nof the CI query by using a numerical bound for similarity\\nresult value as a predicate for selecting eligible rows. A user\\ncan also use SQL ordering clauses, `DESC` or `ASC`, to order\\nresults based on the similarity value that captures the semantic closeness between the relational variables: higher is\\nthe similarity value, closer are these two relational variables.\\nThe UDFs perform three key tasks: (1) processing input relational variables to generate tokens used for training. This\\ninvolves potentially repeating the steps executed during the\\ndata preparation stage, such as creating compound tokens.\\nFor numeric values, one can use the centroid information to\\nidentify the corresponding clusters. For images, the UDF\\nuses the image name to obtain corresponding text tokens,\\n(2) Once the training tokens are extracted, the UDF uses\\nthem to fetch corresponding meaning vectors, and (3) Finally, the UDF uses the fetched vectors to execute similarity computations to generate the final semantic relationship\\n\\nscore.\\nThe basic cognitive UDF operates on a pair of sets (or\\nsequences) of tokens associated with the input relational parameters (note: value of a relational parameter can be a set,\\ne.g., _{_ `Bananas, Apples` _}_, see Figure 1). The core computational operation of a cognitive UDF is to calculate similarity\\nbetween a pair of tokens by computing the cosine distance\\nbetween the corresponding vectors. For two vectors _v_ 1 and\\n_v_ 2, the cosine distance is computed as _cos_ ( _v_ 1 _, v_ 2 ) = _∥vv_ 11 _∥∥·vv_ 22 _∥_ [.]\\nThe cosine distance value varies from 1.0 (very similar) to\\n-1.0 (very dissimilar). For sets and sequences, the individual\\npair-wise similarity values are then aggragated to generate\\nthe result. In case of sequences, computation of the final\\nsimilarity value takes into account the _ordering_ of tokens:\\ndifferent pair-wise distances contribute differently to the final value based on their relative ordering. For example, two\\nfood items, a chicken ~~i~~ tem consisting of (chicken, salt), is\\nnot very similar to a corn ~~i~~ tem consisting of (corn, salt), although both contain salt (however, the corn ~~i~~ tem is closer\\nto chicken ~~i~~ tem than a wheat ~~i~~ tem that contains (wheat,\\nsugar)).\\n\\n\\n**4.2** **Cognitive Intelligence Queries**\\n\\nThe basic UDF and its extensions are invoked by the SQL\\nCI queries to enable semantic operations on relational variables. Each CI query uses the UDFs to execute _nearest_\\n_neighbor_ computations using the vectors from the current\\nword-embedding model. Thus, CI queries provide _approx-_\\n_imate_ answers that _reflect_ a given model. The CI queries\\ncan be broadly classified into four categories as follows:\\n\\n\\n\\n**(1) Similarity/Dissimilarity Queries:** The basic UDF\\nthat compares two sets of relational variables can be integrated into an existing SQL query to form a _similarity_ CI\\nquery. Figure 6 illustrates a SQL CI query that identifies\\nsimilar customers by comparing their purchases. Assume\\nthat `sales` is a table that contains all customer transactions for a credit card company and whose `sales.Items`\\ncolumn contains all items purchased in a transaction (Figure 1). The current query uses a UDF, `similarityUDF()`,\\nthat computes similarity match between two sets of vectors,\\nthat correspond to the items purchased by the corresponding customers. Unlike the food item scenario, the purchased\\nitem list can be viewed as an unordered bag of items; and\\nindividual pair-wise distances contribute equally to the final result. The query shown in Figure 6 uses the similarity score to select rows with related customers and returns\\nan ordered set of similar customer IDs sorted in descending order of their similarity score. This query can be easily\\ntweaked to identify dissimilar customers based on their purchases. The modified CI query will first choose rows whose\\npurchases have lower similarity (e.g., _<_ 0 _._ 3) and if the results are ordered in an ascending form using the SQL `ASC`\\nkeyword, returns customers that are highly dissimilar to a\\ngiven customer (i.e., purchasing very different items). If the\\nresults are ordered in the descending order using the SQL\\n`DESC` keyword, the CI query will return customers that are\\nsomewhat dissimilar to a given customer.\\n\\n```\\nSELECT X.custID, Y.custID, similarityUDF(X.Items,\\nY.Items) AS similarity\\nFROM sales X, sales Y\\nWHERE similarityUDF(X.Items, Y.Items) > 0.5\\nORDER BY similarity DESC\\n\\n```\\n\\n**Figure 6: Example of an CI similarity query: find**\\n**similar customers based on their purchased items**\\n\\n\\nA modified version of the query (not shown) can identify\\nsimilar customers based on their overall purchasing pattern\\nas evidenced in a number of rows. The word embedding\\nmodel creates a vector for each customer name that captures the overall purchases made by that customer. Then,\\nthe customers with similar purchase patterns would have\\nvectors that are close using the cosine distance metric. The\\npattern observed in this query can be applied to other domains as well, e.g., identifying patients that are taking similar drugs, but with different brand names, or identifying\\nfood items with similar ingredients, or recommending mutual funds with similar investment strategies. As we will see\\nin the next section, the similarity query can be applied other\\ndata types, such as images.\\n\\n```\\nSELECT X.custID, Y.custID, Y.Merchant,\\nvalueSimUDF(X.Amount, Y.Amount) AS similarity\\nFROM sales X, sales Y\\nWHERE X.custID=’custA’ AND valueSimUDF(X.Amount,\\nY.Amount) > 0.5 AND X.custID != Y.custID AND X.amount >\\n\\n150.0 AND Y.amount < 100.0\\n\\nORDER BY similarity DESC\\n\\n```\\n\\n**Figure 7: Example of an CI value similarity query:**\\n**find similar transactions using purchased amount for**\\n**comparison**\\n\\n\\n\\n6\\n\\n\\n', 'words': []}\n",
      "\n",
      "{'metadata': {'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref package', 'producer': 'pdfTeX-1.40.17', 'creationDate': 'D:20171221013320Z', 'modDate': 'D:20171221013320Z', 'trapped': '', 'encryption': None, 'file_path': '/Users/ngocduy/Documents/PAPERS/cs_DB/Cognitive Database_ A Step towards Endowing Relational Databases with Artificial Intelligence Capabilities.pdf', 'page_count': 14, 'page': 7}, 'toc_items': [], 'tables': [], 'images': [], 'graphics': [], 'text': '```\\nSELECT X.custID, similarityUDF(X.Items, ‘listeria’) AS\\nsimilarity\\nFROM sales X\\nWHERE similarityUDF(X.Items, ‘listeria’) > 0.3\\nORDER BY similarity DESC\\nLIMIT 10\\n\\n```\\n\\n**Figure 8: Example of a prediction query: find cus-**\\n**tomers that have purchased items affected by a lis-**\\n**teria recall**\\n\\n\\nFigure 7 presents a CI query executing similarity operations using a numeric variable. For the sake of example, assume that no two transactions have the same amount value\\n\\nand each unique numerical value is associated with its own\\nstring token. In this scenario, one wants to identify transactions from the `sales` table (Figure 1): using similarity based\\non the purchase amount (in this case, `200.50` for customer\\n`custA` ). The UDF, `valueSimUDF()`, takes two numeric values\\nas input parameters, and compares them using their overall\\n_context_ (which is captured in their meaning vectors), not\\ntheir numerical values. The most similar amount to `200.50`,\\nwould be `80.10` (for customer `custC` ), as it shares the most\\ncontext (e.g., category, address, merchant, and items). The\\nleast similar amount would be `60.80` as it has completely different context than amount `200.50` . This example also illustrates how one can combine the value-based and semanticbased comparisons in the same SQL query.\\nThe third use case provides an illustration of a _prediction_\\nCI query which uses a model that is externally trained using\\nan unstructured data source or another database (Figure 8).\\nConsider a scenario of a recall of various fresh fruit types due\\nto possible listeria infection. This example assumes that we\\nhave built a word embedding model using the recall notices\\nas an external source. Assume that the recall document lists\\nall fruits impacted by the possible listeria infection, e.g., _Ap-_\\n_ples, Peaches, Plums, Nectarines,.._ . The model will create\\nvectors for all these words and the vector for the word _liste-_\\n_ria_ will be closer to the vectors of _Apples_, _Peaches_, _Plums_,\\netc. Now, we can import this model and use it to query the\\n`sales` database to find out which customers have bought\\nitems that may be affected by this recall, as defined by the\\nexternal source. As Figure 8 shows, the `similarityUDF()`\\nUDF is used to identify those purchases that contain items\\nsimilar to _listeria_, such as _Apples_ . This example demonstrates a very powerful ability of CI queries that enables\\nusers to query a database using a token **not present** in the\\ndatabase (e.g., _listeria_ ). This capability can be applied to\\ndifferent scenarios in which recent, updatable information,\\ncan be used to query historical data. For example, a model\\nbuilt using a FDA recall notices could be used to identify\\nthose customers who have purchased medicines similar to\\nthe recalled medicines.\\n**(2) Inductive Reasoning Queries:** An unique feature\\nof word-embedding vectors is their capability to answer _in-_\\n_ductive reasoning_ queries that enable an individual to reason\\nfrom _part_ to _whole_, or from _particular_ to _general_ [54, 58]. Solutions to inductive reasoning queries exploit latent semantic structure in the trained model via algebraic operations\\non the corresponding vectors. We encapsulate these operations in UDFs to support following five types of inductive\\nreasoning queries: analogies, semantic clustering, analogy\\nsequences, clustered analogies, and odd-man-out [54].\\n\\n\\n```\\nSELECT X.custID, analogyUDF(‘Frozen Goods’,\\n‘custF’,‘Fresh Produce’,X.custID) AS similarity\\nFROM sales X\\nWHERE analogyUDF(‘Frozen Goods’, ‘C3423567’,‘Fresh\\nProduce’,X.custID) > 0.5\\nORDER BY similarity DESC\\n\\n```\\n\\n**Figure 9: Example of an analogy query**\\n\\n\\n_•_ Analogies: Wikipedia defines analogy as a process of\\ntransferring _information_ or _meaning_ from one subject\\nto another. A common way of expressing an analogy is to use relationship between a pair of entities,\\n`source` `1` and `target` `1`, to reason about a possible target entity, `target` `2`, associated with another known\\nsource entity, `source` `2` . An example of an analogy\\nquery is _Lawyer_ : _Client_ :: _Doctor_ :?, whose answer\\nis _Patient_ . To solve an analogy problem of the form\\n( _X_ : _Y_ :: _Q_ :?), one needs to find a token _W_ whose\\nmeaning vector, _V_ _w_, is closest to the ideal response\\nvector _V_ _R_, where _V_ _R_ = ( _V_ _Q_ + _V_ _Y_ _−_ _V_ _x_ ) [54]. Recently,\\nseveral solutions have been proposed to solve this formulation of the analogy query [35, 39, 45]. We have\\nimplemented the 3COSMUL approach [35] which uses\\nboth the absolute distance and direction for identifying\\nthe vector _V_ _W_ as\\n\\n\\n_cos_ ( _V_ _W_ _, V_ _Q_ ) _cos_ ( _V_ _W_ _, V_ _Y_ )\\narg max (1)\\n_W ∈C_ _cos_ ( _V_ _W_ _, V_ _X_ ) + _ϵ_\\n\\n\\nwhere _ϵ_ = 0 _._ 001 is used to avoid the denominator becoming 0. Also, 3COSMUL converts the cosine similarity value of _c_ to [(] _[c]_ [+] 2 [1][)] to ensure that the value being\\n\\nmaximized is non-negative.\\n\\n\\nFigure 9 illustrates a CI query that performs an analogy computation on the relational variables using the\\nUDF `analogyUDF()` . This query aims to find a customer from the `sales` table (Figure 1), whose relationship to the category, `Fresh Produce`, is similar to what\\n`C3423567` has with the category, `Frozen Goods` (i.e. if\\n`C3423567` is the most prolific shopper of frozen goods,\\nfind other customers who are the most prolific shoppers\\nof fresh produce). The `analogyUDF()` UDF fetches vectors for the input variables, and using the 3COSMUL\\napproach, returns the analogy score between a vector\\ncorresponding to the input token and the computed\\nresponse vector. Those rows, whose variables (e.g.,\\n`custID` ) have analogy score greater than a specified\\nbound (0.5), are selected, and returned in descending\\norder of the score. Since analogy operation is implemented using _untyped_ vectors, the `analogyUDF()` UDF\\ncan be used to capture relationships between variables\\nof different types, e.g., images and text.\\n\\n\\n_•_ Semantic Clustering: Given a set of input entities,\\n_{X, Y, Z, ..}_, the semantic clustering process identifies\\na set of entities, _{W, ..}_, that share the most dominant\\ntrait with the input data. The semantic clustering operation has a wide set of applications, including customer segmentation, recommendation, etc. Figure 10\\npresents a CI query which uses a semantic clustering UDF, `semclusterUDF()`, to identify customers that\\n\\n\\n\\n7\\n\\n\\n', 'words': []}\n",
      "\n",
      "{'metadata': {'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref package', 'producer': 'pdfTeX-1.40.17', 'creationDate': 'D:20171221013320Z', 'modDate': 'D:20171221013320Z', 'trapped': '', 'encryption': None, 'file_path': '/Users/ngocduy/Documents/PAPERS/cs_DB/Cognitive Database_ A Step towards Endowing Relational Databases with Artificial Intelligence Capabilities.pdf', 'page_count': 14, 'page': 8}, 'toc_items': [], 'tables': [], 'images': [], 'graphics': [], 'text': '```\\nSELECT X.custID, semclusterUDF(‘custX’, ‘custY’,\\n‘custZ’, X.custID) AS similarity\\nFROM sales X\\n\\nWHERE semclusterUDF(‘custX’,‘custY’, ‘custZ’, X.custID)\\n\\n> 0.5\\n\\nORDER BY similarity DESC\\n\\n```\\n\\n**Figure 10: Example of a semantic clustering query**\\n\\n\\nhave the most common attributes with the input set of\\ncustomers, e.g., `custF`, `custM`, and `custR` . For solving\\na semantic clustering query of the form, ( _X, Y, Z_ ::?),\\none needs to find a set of tokens _S_ _w_ = _{W_ 1 _, W_ 2 _, .., W_ _i_ _}_\\nwhose meaning vectors _V_ _w_ _i_ are most similar to the _cen-_\\n_troid_ of vectors _V_ _X_ _, V_ _Y_ _,_ and _V_ _Z_ (the centroid vectors\\ncaptures the dominant features of the input entities).\\n\\n\\n_•_ Analogy Sequences and Clustered Analogies: These\\ntwo types of inductive reasoning queries, analogy sequences and clustered analogies, can be implemented\\nby combining strategies for semantic clustering and\\nanalogies. The analogy sequence query takes as input a\\nsequence of analogy pairs, with the _same_ source entity\\nand aims to identify a set of target entities that exhibit\\nthe same relationships with the source entity as the\\nset of input target entities. To answer this query, one\\nneeds to first compute the centroid vector of the input\\ntarget vectors and then use it to answer the following\\nanalogy problem: _source_ : _input_ ~~_c_~~ _entroid_ :: _source_ :?\\nusing the 3COSMUL approach to return a set of target\\nentities.\\n\\n\\nUnlike analogy sequences, the clustered analogy operation takes as input a set of analogy pairs, each with different ( _source_ _i_ _, target_ _i_ ) entity pairs and aims to predict a set of ( _source_ _o_ _, target_ _o_ ) pairs that shares the\\nfollowing relationships with the input sequence: the\\nresult set of source entities, _source_ _o_, share the dominant trait with the input set of source entities, _source_ _i_,\\nand each resultant target entity, _target_ _o_, is related to\\nthe corresponding source entity via the analogy relationship. Therefore, to solve clustered analogy queries,\\nwe first perform semantic clustering to compute the result source entities, _source_ _o_, and then for each result\\nsource entity, we compute a set of target entities using\\nthe analogy sequence approach. Unlike the analogy\\nsequences query, the result of the clustered analogy\\nquery is a set of sets: a set of source entities, each\\nassociated with a set of target entities.\\n\\n\\n_•_ Odd-man-out [2] : As the name suggests, given a set of\\nitems, the odd-man-out query identifies an item that\\nis semantically different from the remaining items [18].\\nThe odd-man-out query can be viewed as a complementary query to semantic clustering. For example,\\ngiven a set of animals, _{_ Hippopotamus, Giraffe, Elephant, and Lion _}_, one answer can be Lion, as it is\\nonly carnivorous animal in the collection. However, if\\nthe word-embedding model of these animals captures\\ntheir locations, Elephant may be the answer if it is\\nnot present in that location. Thus, the odd-man-out\\n\\n\\n2 Odd-man-out is often used in practice to quantify human\\nintelligence [18].\\n\\n\\n```\\nSELECT X.Category, MAX(X.Amount)\\nFROM sales X\\nWHERE similarityUDF(‘Merchant Y’,X.Merchant) > 0.5\\nGROUP BY X.Category\\n\\n```\\n\\n**Figure 11: Example of a cognitive OLAP (aggrega-**\\n**tion) query**\\n\\n\\nexecution requires context-specific semantic clustering\\nover the meaning vectors. Specifically, the clustering\\naims to partition the data into two clusters, one with\\nonly one member, and the other containing the remaining data. One obvious application of the odd-man-out\\nCI query would anomaly detection, e.g., for identifying\\na fraudalant transaction for a customer.\\n\\n\\n**(3) Cognitive OLAP Queries:** Figure 11 presents a simple example of using semantic similarities in the context of\\na traditional SQL aggregation query. This CI query aims to\\nextract the maximum sale amount for each product category\\nin the `sales` table for each merchant that is similar to a specified merchant, `Merchant` `Y` . The result is collated using the\\nvalues of the product category. As illustrated earlier, the\\nUDF `similarityUDF` can also be used for identifying customers that are different than the specified merchant. The\\nUDF can use either an externally trained or locally trained\\nmodel. This query can be easily adapted to support other\\nSQL aggregation functions such as `MAX()`, `MIN()`, and `AVG()` .\\nThis query can be further extended to support `ROLLUP` operations over the aggregated values [27].\\nWe are also exploring integration of cognitive capabilities\\ninto additional SQL operators, e.g., `IN` and `BETWEEN` . For\\nexample, one or both of the value ranges for the `BETWEEN`\\noperator can be computed using a similarity CI query. For\\nan `IN` query, the associated set of choices can be generated by\\na similarity or inductive reasoning queries. Another intriguing extension involves using contextual similarities to choose\\n_members_ of the schema dimension hierarchy for aggregation\\noperations like `ROLLUP` or `CUBE` . For example, instead of aggregating over all quarters for all years, one can use only\\nthose quarters that are semantically similar to a specified\\nquarter.\\n**(4) Cognitive Extensions to the Relational Data Model:**\\nThere are powerful extensions to SQL that are enabled by\\nword vectors. For this we need the ability to refer to constituent tokens (extracted during textification) in columns\\nof rows, in whole rows and in whole relations. The extension\\nis via a declaration, in the `FROM` clause, of the form `Token`\\n`e1` that states that variable _e_ 1 refers to a token. To _locate_\\n\\na token we use, in the `WHERE` clause, predicates of the form\\n`contains(E, e1)` where `E` can be a column in a row (e.g.,\\n`EMP.Address` ), a whole row (e.g., `EMP.*` ) or a whole relation\\n(e.g., `EMP` ). With this extension we can easily express queries\\nsuch as asking for an employee whose Address contains a token which is very close to a token in a row in the `DEPT` relation (Figure 12). Furthermore, we can also extend SQL with\\nrelational variables, say of the form `$R` and column variables,\\nsay `X`, whose names are not specified at query writing time;\\nthey are bound at runtime. We can then use these variables\\nin queries, in conjunction with `Token` variables. This enables database querying without explicit schema knowledge\\nwhich is useful for exploring a database. Interestingly, the\\n\\n\\n\\n8\\n\\n\\n', 'words': []}\n",
      "\n",
      "{'metadata': {'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref package', 'producer': 'pdfTeX-1.40.17', 'creationDate': 'D:20171221013320Z', 'modDate': 'D:20171221013320Z', 'trapped': '', 'encryption': None, 'file_path': '/Users/ngocduy/Documents/PAPERS/cs_DB/Cognitive Database_ A Step towards Endowing Relational Databases with Artificial Intelligence Capabilities.pdf', 'page_count': 14, 'page': 9}, 'toc_items': [[1, '5 Cognitive Queries in Practice', 9]], 'tables': [{'bbox': (339.53619384765625, 58.15727996826172, 514.8656616210938, 160.3067169189453), 'rows': 7, 'columns': 8}, {'bbox': (370.01434326171875, 65.63287353515625, 489.15374755859375, 100.06693267822266), 'rows': 5, 'columns': 4}], 'images': [{'number': 34, 'bbox': Rect(324.40655517578125, 438.294921875, 380.92626953125, 484.9291687011719), 'transform': (56.51969909667969, 0.0, -0.0, 46.634246826171875, 324.40655517578125, 438.294921875), 'width': 600, 'height': 495, 'colorspace': 3, 'cs-name': 'DeviceRGB', 'xres': 96, 'yres': 96, 'bpc': 8, 'size': 61212, 'has-mask': False}], 'graphics': [], 'text': 'notation `$R.X` is basically syntactic sugar. A software translation tool can substitute for `$R.X` an actual table name and\\nan actual column. Then, perform the query for each such\\nsubstitution and return the _union_ of the results [8].\\n\\n```\\nSELECT EMP.Name, EMP.Salary, DEPT.Name\\nFROM EMP, DEPT, Token e1, e2\\nWHERE contains(EMP.Address, e1) AND\\ncontains(DEPT.*, e2) AND\\ncosineDistance(e1, e2) > 0.75\\n\\n```\\n\\n**Figure 12: Example of an SQL query with entities**\\n\\n\\nLastly, one may wonder how numeric bounds on UDFs\\n(e.g., `cosineDistance(e1, e2) > 0.75` in Figure 12) are\\ndetermined. The short answer is that these bounds are\\n\\napplication dependent, much like hyperparameters in machine learning. One learns these by exploring the underlying\\ndatabase and running experiments. In the future, one can\\nenvision a tool that can guide users to select an appropriate\\nnumeric bound for a particular CI query.\\n\\n\\n**5.** **COGNITIVE QUERIES IN PRACTICE**\\n\\nWe now illustrate some unique capabilities of our cognitive database system by discussing a scenario in which CI\\nqueries are used to gain novel insights from a multi-modal relational database. [3] In this scenario, we consider a database\\nof national parks across multiple countries, with links to images of animals in the associated national parks (Figure 13).\\nWe use images from the open source Image database, ImageNet [16], to populate our database. We use this database\\nto present results from inductive reasoning CI queries using\\nour Spark 2.2.0 based prototype on an Intel Xeon E5-2680\\nsystem. Our prototype is implemented in Scala and supports\\nqueries written in either Scala or Python using Spark SQL,\\nSpark Dataframes, or Python pandas SQLite interfaces. Although the database under evaluation is fairly simple, its architecture is similar to many other real life databases, e.g., a\\nmulti-modal patient database with text fields describing patient characteristics and image fields referring to associated\\nimages (e.g., radiology or FMRI images), or an insurance\\nclaims database with text fields containing the claim information and image fields storing supporting pictures (e.g.,\\ncar collision photos).\\nFigure 13(A) presents the original relational table as created by an user. It contains only text fields that list paths to\\nthe images and provide additional information on every image. This table, other than the image path, does not provide\\nany details on the referred images. To create a shared word\\nembedding model from the text and images, we employ the\\nautomatic tag generator approach outlined in Section 3.1.\\nFigure 14 presents the workflow of extracting image features from the referred images. Each image in the database\\n(e.g., a Lion) is first uploaded to the IBM Watson Visual\\nRecognition System (VRS) [30] for classification and text\\ndescription. The Watson system’s JSON response is then\\nparsed, and a set of text attributes for the input image is\\nextracted. These attributes form the features of the images\\nand are added to the original table to create a training version of the table (Figure 13(B)). This training table can be\\n\\n\\n3 Due to space limitations, we focus only on certain types of\\nqueries.\\n\\n\\n|Picture ID|National Park|Country|Image Path|\\n|---|---|---|---|\\n|PK_01|Corbett|India|Img_01.JPEG|\\n|PK_05|Kruger|South Africa|Img_05.JPEG|\\n|PK_09|Sunderbans|India|Img_09.JPEG|\\n|PK_11|Serengeti|Tanzania|Img_11.JPEG|\\n\\n\\n|(A) Original Table|Col2|Col3|Col4|Col5|Col6|Col7|Col8|\\n|---|---|---|---|---|---|---|---|\\n|Picture ID<br>National Park<br>Country<br>Image Path<br>PK_01<br>Corbett<br>India<br>Img_01.JPEG<br>PK_05<br>Kruger<br>South Africa<br>Img_05.JPEG<br>PK_09<br>Sunderbans<br>India<br>Img_09.JPEG<br>PK_11<br>Serengeti<br>Tanzania<br>Img_11.JPEG<br>(B) Training Table|Picture ID<br>National Park<br>Country<br>Image Path<br>PK_01<br>Corbett<br>India<br>Img_01.JPEG<br>PK_05<br>Kruger<br>South Africa<br>Img_05.JPEG<br>PK_09<br>Sunderbans<br>India<br>Img_09.JPEG<br>PK_11<br>Serengeti<br>Tanzania<br>Img_11.JPEG<br>(B) Training Table|Picture ID<br>National Park<br>Country<br>Image Path<br>PK_01<br>Corbett<br>India<br>Img_01.JPEG<br>PK_05<br>Kruger<br>South Africa<br>Img_05.JPEG<br>PK_09<br>Sunderbans<br>India<br>Img_09.JPEG<br>PK_11<br>Serengeti<br>Tanzania<br>Img_11.JPEG<br>(B) Training Table|Picture ID<br>National Park<br>Country<br>Image Path<br>PK_01<br>Corbett<br>India<br>Img_01.JPEG<br>PK_05<br>Kruger<br>South Africa<br>Img_05.JPEG<br>PK_09<br>Sunderbans<br>India<br>Img_09.JPEG<br>PK_11<br>Serengeti<br>Tanzania<br>Img_11.JPEG<br>(B) Training Table|Picture ID<br>National Park<br>Country<br>Image Path<br>PK_01<br>Corbett<br>India<br>Img_01.JPEG<br>PK_05<br>Kruger<br>South Africa<br>Img_05.JPEG<br>PK_09<br>Sunderbans<br>India<br>Img_09.JPEG<br>PK_11<br>Serengeti<br>Tanzania<br>Img_11.JPEG<br>(B) Training Table|Picture ID<br>National Park<br>Country<br>Image Path<br>PK_01<br>Corbett<br>India<br>Img_01.JPEG<br>PK_05<br>Kruger<br>South Africa<br>Img_05.JPEG<br>PK_09<br>Sunderbans<br>India<br>Img_09.JPEG<br>PK_11<br>Serengeti<br>Tanzania<br>Img_11.JPEG<br>(B) Training Table|Picture ID<br>National Park<br>Country<br>Image Path<br>PK_01<br>Corbett<br>India<br>Img_01.JPEG<br>PK_05<br>Kruger<br>South Africa<br>Img_05.JPEG<br>PK_09<br>Sunderbans<br>India<br>Img_09.JPEG<br>PK_11<br>Serengeti<br>Tanzania<br>Img_11.JPEG<br>(B) Training Table|Picture ID<br>National Park<br>Country<br>Image Path<br>PK_01<br>Corbett<br>India<br>Img_01.JPEG<br>PK_05<br>Kruger<br>South Africa<br>Img_05.JPEG<br>PK_09<br>Sunderbans<br>India<br>Img_09.JPEG<br>PK_11<br>Serengeti<br>Tanzania<br>Img_11.JPEG<br>(B) Training Table|\\n|Picture ID|Image Path|National Park|Country|Animal Name<br>|Class|Dietary Habit|color|\\n|PK_01|Img_01.JPEG|Corbett|India|Tiger<br>|Mammal|Carnivorous|Yellow|\\n|PK_05|Img_05.JPEG|Kruger|South Africa|Rhinoceros<br>|Mammal|Herbivores|Gray|\\n|PK_09|Img_08.JPEG|Sunderbans|India|Indian Gharial<br>|Reptile|Carnivorous|Gray|\\n|PK_11|Img_11.JPEG|Serengeti|Tanzania|Crocodile<br>|Reptile|Carnivorous|Gray|\\n|(C) Sentence for training|(C) Sentence for training|(C) Sentence for training|(C) Sentence for training|(C) Sentence for training|(C) Sentence for training|(C) Sentence for training|(C) Sentence for training|\\n\\n\\n\\n**Figure 14:** **Illustration of workflow to generate a**\\n_**Text Attribute Database**_ **of images using the IBM**\\n**Watson Visual Recognition Service (VRS) using a**\\n**sample image from Imagenet dataset**\\n\\n\\nOnce the meaning vectors are computed they can be used\\nto evaluate semantic relationships between values in the\\n_original_ relational table. For example, if one were to compare National Parks, `Serengati` and `Sunderbans` would be\\nthe most similar as they both share multiple image features.\\nIt should be noted that one can not get this insight by using standard SQL queries as the original table does not have\\nany image information. Further, as many values in the training database are syntactically different (e.g., `Crocodile` and\\n`Indian Gharial` ), existing SQL systems will fail to extract\\nany semantic similarities.\\nThe first two examples of SQL CI queries over multimodal data assume that the users have access to the training database (Figure 13(B)). Figure 15 illustrates an analogy\\n\\n\\n\\n“ PK_01 Img_01.JPEG Corbett  India Tiger Mammal Carnivorous Yellow”\\n\\n\\nTraining a shared model across features from multi-modal data\\n\\n\\n**Figure 13: Steps in training a multi-modal database**\\n**with text and image fields**\\n\\n\\neither hidden or exposed to the user. The training table is\\nthen converted to the textual representation (Figure 13(C))\\nto build the text corpus for training the word embedding\\nmodel. Each sentence in the text corpus includes both original non-image (e.g., `Corbett` ) and extracted image features\\n(e.g., `Tiger`, or `Carnivorous` ). In the resulting multi-modal\\nword embedding model, the non-image features will contribute to the meaning of image features and vice versa,\\nand all meaning vectors will be uniformly represented using\\nvectors of dimension _d_ = 200.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\"{\\\\n\\\\\"images\\\\\": [\\\\n {\\\\n \\\\\"image\\\\\": \\\\\"./ **n00015388_39388.JPEG** \\\\\", \\\\n\\n\\\\\"classifiers\\\\\": [\\\\n {\\\\n \\\\\"classes\\\\\": [\\\\n {\\\\n \\\\\"score\\\\\": **0.969**, \\\\n\\n\\\\\"class\\\\\": \\\\\"lion\\\\\", \\\\n\\\\\"type_hierarchy\\\\\":\\n\\\\\" **/animal/mammal/carnivore/feline/big cat/lion** \\\\\"\\\\n}, \\\\n {\\\\n\\n\\\\\"score\\\\\": 0.978, \\\\n \\\\\"class\\\\\": \\\\\"big cat\\\\\"\\\\n}, \\\\n {\\\\n \\\\\"score\\\\\": 0.979,\\n\\\\n \\\\\"class\\\\\": \\\\\"feline\\\\\"\\\\n}, \\\\n  {\\\\n \\\\\"score\\\\\": 0.98, \\\\n \\\\\"class\\\\\":\\n\\\\\"carnivore\\\\\"\\\\n }, \\\\n {\\\\n \\\\\"score\\\\\": 0.98, \\\\n \\\\\"class\\\\\":\\n\\\\\"mammal\\\\\"\\\\n}, \\\\n {\\\\n \\\\\"score\\\\\": 0.98, \\\\n \\\\\"class\\\\\": \\\\\"animal\\\\\"\\\\n}, \\\\n\\n{\\\\n \\\\\"score\\\\\": 0.942, \\\\n   \\\\\"class\\\\\": \\\\\" **yellow color** \\\\\"\\\\n}, \\\\n {\\\\n\\n\\\\\"score\\\\\": 0.887, \\\\n   \\\\\"class\\\\\": \\\\\" **pale yellow color** \\\\\"\\\\n}\\\\n], \\\\n\\n\\n**[n00015388_39388.JPEG]** \\\\\"classifier_id\\\\\": \\\\\" **default** \\\\\", \\\\n \\\\\"name\\\\\": \\\\\"default\\\\\"\\\\n}\\\\n]\\\\n }\\\\n],\\n\\\\n \\\\\"custom_classes\\\\\": 0, \\\\n \\\\\"images_processed\\\\\": 1\\\\n}\"\\n\\n\\n\\n\\n[“ **n00015388_39388** . **JPEG** ”,\\n“animal”,\\n“mammal”,\\n“carnivore feline big_cat”,\\n“lion”,\\n“yellow pale_yellow”]\\n\\n\\n\\n9\\n\\n\\n', 'words': []}\n",
      "\n",
      "{'metadata': {'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref package', 'producer': 'pdfTeX-1.40.17', 'creationDate': 'D:20171221013320Z', 'modDate': 'D:20171221013320Z', 'trapped': '', 'encryption': None, 'file_path': '/Users/ngocduy/Documents/PAPERS/cs_DB/Cognitive Database_ A Step towards Endowing Relational Databases with Artificial Intelligence Capabilities.pdf', 'page_count': 14, 'page': 10}, 'toc_items': [], 'tables': [], 'images': [{'number': 40, 'bbox': Rect(378.3246765136719, 244.1920623779297, 419.5528869628906, 295.8243713378906), 'transform': (41.22821044921875, 0.0, -0.0, 51.63230895996094, 378.3246765136719, 244.1920623779297), 'width': 500, 'height': 392, 'colorspace': 3, 'cs-name': 'ICCBased(RGB,Adobe RGB (1998))', 'xres': 96, 'yres': 96, 'bpc': 8, 'size': 129796, 'has-mask': False}, {'number': 15, 'bbox': Rect(163.31964111328125, 533.1849975585938, 211.26486206054688, 576.335693359375), 'transform': (47.945220947265625, 0.0, -0.0, 43.150718688964844, 163.31964111328125, 533.1849975585938), 'width': 337, 'height': 362, 'colorspace': 3, 'cs-name': 'ICCBased(RGB,sRGB IEC61966-2.1)', 'xres': 96, 'yres': 96, 'bpc': 8, 'size': 37378, 'has-mask': False}, {'number': 14, 'bbox': Rect(112.42137145996094, 533.1849975585938, 158.57028198242188, 576.335693359375), 'transform': (46.14891815185547, 0.0, -0.0, 43.150718688964844, 112.42137145996094, 533.1849975585938), 'width': 360, 'height': 288, 'colorspace': 3, 'cs-name': 'ICCBased(RGB,sRGB IEC61966-2.1)', 'xres': 96, 'yres': 96, 'bpc': 8, 'size': 32374, 'has-mask': False}, {'number': 44, 'bbox': Rect(427.123779296875, 310.3270263671875, 471.8215637207031, 353.77398681640625), 'transform': (44.69779586791992, 0.0, -0.0, 43.44694519042969, 427.123779296875, 310.3270263671875), 'width': 500, 'height': 357, 'colorspace': 3, 'cs-name': 'ICCBased(RGB,sRGB IEC61966-2.1)', 'xres': 96, 'yres': 96, 'bpc': 8, 'size': 78847, 'has-mask': False}, {'number': 29, 'bbox': Rect(328.63275146484375, 244.0497589111328, 365.78997802734375, 295.6590881347656), 'transform': (37.15723419189453, 0.0, -0.0, 51.60932540893555, 328.63275146484375, 244.0497589111328), 'width': 500, 'height': 447, 'colorspace': 3, 'cs-name': 'ICCBased(RGB,sRGB IEC61966-2.1)', 'xres': 96, 'yres': 96, 'bpc': 8, 'size': 195488, 'has-mask': False}, {'number': 41, 'bbox': Rect(432.0876159667969, 244.04977416992188, 469.4629211425781, 295.3561706542969), 'transform': (37.37531280517578, 0.0, -0.0, 51.30640411376953, 432.0876159667969, 244.04977416992188), 'width': 250, 'height': 175, 'colorspace': 3, 'cs-name': 'ICCBased(RGB,sRGB IEC61966-2.1)', 'xres': 96, 'yres': 96, 'bpc': 8, 'size': 4641, 'has-mask': False}, {'number': 13, 'bbox': Rect(64.7798843383789, 533.6061401367188, 107.71611022949219, 576.7568359375), 'transform': (42.936222076416016, 0.0, -0.0, 43.150718688964844, 64.7798843383789, 533.6061401367188), 'width': 1057, 'height': 1200, 'colorspace': 3, 'cs-name': 'ICCBased(RGB,sRGB IEC61966-2.1)', 'xres': 96, 'yres': 96, 'bpc': 8, 'size': 69328, 'has-mask': False}, {'number': 42, 'bbox': Rect(326.5684814453125, 309.98858642578125, 369.03314208984375, 353.435546875), 'transform': (42.46467590332031, 0.0, -0.0, 43.44694519042969, 326.5684814453125, 309.98858642578125), 'width': 500, 'height': 375, 'colorspace': 3, 'cs-name': 'ICCBased(RGB,sRGB IEC61966-2.1)', 'xres': 96, 'yres': 96, 'bpc': 8, 'size': 156637, 'has-mask': False}, {'number': 43, 'bbox': Rect(378.3246765136719, 309.98858642578125, 420.6737365722656, 353.435546875), 'transform': (42.349056243896484, 0.0, -0.0, 43.44694519042969, 378.3246765136719, 309.98858642578125), 'width': 500, 'height': 333, 'colorspace': 3, 'cs-name': 'ICCBased(RGB,sRGB IEC61966-2.1)', 'xres': 96, 'yres': 96, 'bpc': 8, 'size': 119534, 'has-mask': False}], 'graphics': [], 'text': 'are similar to every image in the set of user chosen images.\\nSuch images share one or more features with the input set of\\nimages. For this query, we select images of a lion, a vulture,\\nand a shark as the input set and use the `combinedAvgSim()`\\nUDF to identify images that are similar to all these three\\nimages. Although the input images display animals from\\nthree different classes, they share one common feature: all\\nthree animals are carnivorous. The UDF computes the average vector from the three input images and then selects\\nthose images whose vectors are similar to the computed average vector with similarity score higher than 0.75. Figure 17\\nshows the top three image results: andean condor, glutton\\nwolverine, and tyra. Although these animals are from different classes, they all are carnivores, a feature that is shared\\nwith the animals from the input set.\\n\\n\\nInput\\n\\n\\n\\nOutput Table\\n\\n\\nn02512053_1493 n02512053_6867 n02512830_2279\\n\\n\\n\\n**Find all images whose classD satisfies the**\\n**analogy query [reptile : monitor_lizard ::**\\n**aquatic_vertebrate : ?] using analogyQuery**\\n**UDFhaving similarity score greater than 0.5.**\\n**Sort the results in descending order of their**\\n**similarity score.**\\n\\n\\nSELECT X.imagename,\\nX.classB, X.classC, X.classD,\\n**analogyQuery(’reptile’,’monitor_lizard’,’**\\n**aquatic_vertebrate’,X.classD)**\\n\\n**AS Score**\\n\\nFROM ImageDataTable X\\n\\nWHERE\\n\\n**(analogyQuery(’reptile’,’monitor_lizard’,**\\n**’aquatic_vertebrate’, X.classD) > 0.5)**\\n\\nORDER BY Score DESC\\n\\n\\n\\n**Figure 15: Analogy queries over images**\\n\\n\\nquery over images, while Figure 16 illustrates an analogy sequence query. In both cases, the CI queries are formulated\\nusing UDFs, `analogyQuery()` and `analogySequence()`, that\\ntake values from the training database as input. In case of\\nthe analogy query, the goal is to find all images whose `classD`\\nfeature (i.e. extracted name) has the same relationship to its\\n`classC` feature (i.e. class `aquatic` ~~`v`~~ `ertebrate` ) as the specified relationship, `reptile::monitor` `lizard` . For each row\\nin the table, the UDF first fetches meaning vectors for the\\ninput parameters and uses the 3COSMUL approach to find\\na relational value whose vector maximizes the analogy similarity score as defined in Equation 1. The SQL query returns\\nthe corresponding images, whose similarity score is higher\\nthan 0.5 and reports them in a descending order of similarity score. Figure 15 presents an output fragment of the CI\\nquery and the corresponding images of `spiny` `finned` `fish` .\\nThe analogy sequence query (Figure 16) uses a UDF that\\noperates on a sequence of analogy pairs that share the source\\nentity (e.g., `mammal` ), but has different target entities, (e.g.,\\n`jackal` and `mongoose` ). The UDF converts the analogy sequence problem into a traditional analogy problem by first\\ncomputing the average vector of the target entities and then\\nusing it in the 3COSMULT approach. Figure 16 presents the\\nSQL CI query, the analogy sequence UDF, and its output\\n(images of grey fox).\\n\\n\\n\\nn00015388_18458 n01316422_255 n01315581_997\\n\\n\\nOutput\\n\\n\\n\\n**Find all images whose similarity to user**\\n**chosen images of** _**[lion, vulture, shark]**_\\n**using combinedAvgSim UDF is greater**\\n**than 0.75. Exclude the input images and**\\n**sort the result in descending order of**\\n**their similarity score** **.**\\n\\n\\nSELECT X.imageName,\\n**combinedAvgSim(X.imagename,**\\n**’n00015388_18458.jpeg’,**\\n**’n01316422_255.jpeg’,**\\n**’n01315581_997.jpeg’) AS SimScore**\\nFROM ImageDataTable X WHERE\\n\\n(X.imagename <> ’n00015388_18458.jpeg’) AND\\n(X.imagename <> ’n00015388_19237.jpeg’) AND\\n(X.imagename <> ’n00015388_18797.jpeg’) AND\\n**(combinedAvgSim(X.imagename,**\\n**’n00015388_18458.jpeg’,**\\n**’n01316422_255.jpeg’,**\\n**’n01315581_997.jpeg’) > 0.75)**\\n\\n\\nORDER BY SimScore DESC\\n\\n\\n\\nn01324431_7056\\nandean_condor, tayra\\n\\n\\n\\nn01604330_12473\\nandean_condor, condor\\nsloth_bear\\n\\n\\n\\nn01316422_1684\\nglutton_wolverine\\n\\n\\n\\nn02075612_7257\\n\\n[grey_fox]\\n\\n\\n\\n**Figure 17: Semantic clustering of images**\\n\\n\\nThe final example demonstrates the use of an external\\nsemantic model for querying a multi-modal database. In\\nthis scenario, we first train a word embedding model from\\nan external knowledge base derived from Wikipedia. Similar to the model trained from the database, the external\\nmodel assigns _d_ dimensional meaning vectors to unique tokens (for the external model, we use _d_ = 200). From the\\nwikipedia model, we select a token associated with a concept\\n`Hypercarnivore`, which refers to a class of animals whose\\ndiet has more than 70% meat. Examples of hypercarnivores include lions, sharks, polar bears, crocodiles, hyenas,\\netc. Therefore, in our model, the Hypercarnivore meaning vector is related to meaning vectors of tokens `shark`,\\n`crocodiles`, etc. For this query, we employ this externally\\ntrained model to extract images that are similar to the concept `Hypercarnivore` . The UDF `proximityAvgForExtKB()`\\nuses the external model, finds images from the database\\nwhose classD features (i.e., names) are related to\\n`Hypercarnivore`, and returns those images whose similarity score is higher than 0.5. Figure 18 shows the CI query\\nand its result: pictures of hyenas, who are members of the\\nhypercarnivore class [4] . This example also demonstrates the\\nunique capability of cognitive databases that allows querying a database using a token not present in the database.\\nIn our case, both the original and training databases do not\\ncontain the token `Hypercarnivore` .\\n\\n\\n4 one of the images is a picture of a big dog which has been\\nmislabelled as an hyena by Watson VRS.\\n\\n\\n\\n**Find all images whose classD satisfies**\\n**the analogy query [ (mammal : jackal),**\\n**(mammal : mongoose) :: mammal : ?]**\\n**having similarity score greater than**\\n**0.5. Filter out images of common**\\n\\n**carnivorous animals and sort the**\\n\\n**results in descending order of their**\\n**similarity score.**\\n\\n\\nSELECT X.imagename, **analogySequence**\\n**(’mammal’, ’jackal’,’mammal’,**\\n**’mongoose’,’mammal’,X.ClassD)**\\nAS AnalogyScore\\nFROM ImageDataTable X WHERE\\n**(stringPresent(X.classD, ’tigress’) == 0) AND**\\n\\n**….**\\n\\nstringPresent(X.classD, ’jackal’) == 0) AND\\n(stringPresent(X.classD, ’mongoose’) == 0) AND\\n( **analogySequence(’mammal’, ’jackal’,**\\n**’mammal’,’mongoose’,’mammal’,X.classD,) 0.5)**\\nORDER BY AnalogyScore DESC\\n\\n\\n\\nn01314663_1129\\n\\n[grey_fox, kit_fox]\\n\\n\\n\\nOutput\\n\\n\\nn02075612_340\\n\\n[grey_fox]\\n\\n\\n\\nn01315805_3451\\n\\n[grey_fox]\\n\\n\\n\\nn01324431_4949\\n\\n[silver_fox,kit_fox,grey_fox]\\n\\n\\n\\n**Figure 16: Analogy sequence queries over images**\\n\\n\\nThe next example (Figure 17) illustrates execution of a semantic clustering query on the _original_ multi-modal database\\ntable. The goal of this query is to identify all images that\\n\\n\\n\\n10\\n\\n\\n', 'words': []}\n",
      "\n",
      "{'metadata': {'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref package', 'producer': 'pdfTeX-1.40.17', 'creationDate': 'D:20171221013320Z', 'modDate': 'D:20171221013320Z', 'trapped': '', 'encryption': None, 'file_path': '/Users/ngocduy/Documents/PAPERS/cs_DB/Cognitive Database_ A Step towards Endowing Relational Databases with Artificial Intelligence Capabilities.pdf', 'page_count': 14, 'page': 11}, 'toc_items': [[2, '5.1 Optimizing Cognitive Intelligence Queries', 11], [1, '6 Related Work', 11]], 'tables': [], 'images': [{'number': 7, 'bbox': Rect(130.61337280273438, 131.94029235839844, 199.54478454589844, 172.47589111328125), 'transform': (68.93141174316406, 0.0, -0.0, 40.53559875488281, 130.61337280273438, 131.94029235839844), 'width': 500, 'height': 333, 'colorspace': 3, 'cs-name': 'ICCBased(RGB,Adobe RGB (1998))', 'xres': 96, 'yres': 96, 'bpc': 8, 'size': 110324, 'has-mask': False}, {'number': 6, 'bbox': Rect(61.33072280883789, 131.94029235839844, 124.09552001953125, 172.47589111328125), 'transform': (62.764801025390625, 0.0, -0.0, 40.53559875488281, 61.33072280883789, 131.94029235839844), 'width': 240, 'height': 155, 'colorspace': 3, 'cs-name': 'ICCBased(RGB,sRGB IEC61966-2.1)', 'xres': 96, 'yres': 96, 'bpc': 8, 'size': 25891, 'has-mask': False}], 'graphics': [], 'text': 'n01316422_10406\\n\\n[hyena, spotted_hyena]\\n\\n\\n\\nn01316422_10446\\n\\n[hyena, spotted_hyena]\\n\\n\\nn01317541_6440\\n\\n[hyena, water_dog_dog,\\nspotted_hyena]\\n\\n\\n\\nOutput\\n\\n\\nn01321579_5386\\n\\n[hyena, spotted_hyena]\\n\\n\\n\\nn02075612_2316\\n\\n[hyena, pouched_mammal,\\nspotted_hyena, bear_cub]\\n\\n\\n\\n**Find all images of animals whose**\\n**classD similarity score to the Concept**\\n**of ‘‘Hypercarnivore\" of Wikipedia**\\n**using proximityAvgExtKB UDF is**\\n**greater than 0.5. Exclude images that**\\n**are already tagged as carnivore,**\\n**herbivore, omnivore or scavenger. Sort**\\n**the results in descending order of their**\\n**similarity score.**\\n\\n\\n\\ncan be converted into a single matrix-vector multiplication operation. This can be generalized to a matrixmatrix multiplication operation to enable distance computations between two sets of vectors.\\n\\n\\n_•_ Reducing redundant computations: For a given vector,\\nwe can first identify a candidate set of vectors that\\nare spatially closer to it in the _d_ dimensional vector\\nspace using either locality sensitive hashing (LSH) [9],\\nor clustering via the Spherical K-Means algorithm [17].\\nWe can then invoke distance calculations on the candidate set to compute precise distances. In the LSH\\napproach, the _d_ dimension vector locations are mapped\\nto bit-vector _signatures_ of length _d_ via projecting them\\non random planes. For a given vector, spatially closer\\nvectors can be identified by choosing those with small\\nhamming distance (1 or 2) between their corresponding signatures. In the K-Means approach, one can use\\nthe centroid information to identify a candidate set of\\nspatially close vectors. Both approaches can also be\\naccelerated using either SIMD functions or GPUs [7].\\n\\n\\n_•_ Using relational query optimization approaches: One\\ncan also reduce redundant computations by using relational view that pre-selects rows from a table based\\non certain criteria. In addition, once the candidate\\nset of SQL variables is known, the SQL query engine\\ncan pre-compute the pair-wise distances and use the\\ncached results during execution of UDFs later.\\n\\n\\n_•_ Using hardware acceleration and parallelization: The\\ncore nearest-neighbor distance computations, namely,\\ndotproduct, matrix-vector, and matrix-matrix computations can be accelerated via hardware accelerators\\nsuch as on-chip SIMD or using GPUs [6]. Most numerical libraries such as MKL, ESSL, or OpenBLAS provide hardware accelerated matrix computation kernels.\\nFurther, the nearest neighbor computations can be\\nalso parallelized either using CPU-based multithreading (e.g., using pthreads) or distributing it over a cluster of machines using a distributed infrastructure such\\nas the Apache Spark.\\n\\n\\nOptimizations of the cognitive intelligence queries is an\\nopen problem and is the current focus of our activities.\\n\\n\\n**6.** **RELATED WORK**\\n\\n**Language Embedding:** Over the past few years, a number of methods have been introduced for obtaining a vector\\nrepresentation of words in a language [5], called _language_\\n_embedding_ . The methods range from _brute force_ learning\\nby various types of neural networks (NNs) [5], to log-linear\\nclassifiers [43] and to various matrix formulations, such as\\nmatrix factorization techniques [36]. Lately, Word2Vec [42,\\n45, 44, 35] has gained prominence as the vectors it produces appear to capture syntactic as well semantic properties of words. The exact mechanism employed by Word2Vec\\nand suggestions for alternatives are the subject of much research [46, 19, 35]. Although Word2Vec has gained much\\nprominence it is one of many possible methods for generating word representing vectors. For example, GloVe [51]\\nalso builds word embeddings by a function optimization approach over the word co-occurrence matrix. Vectors may be\\nassociated with larger bodies of text such as paragraphs and\\n\\n\\n\\n**SELECT X.imagename, proximityAvgExtKB**\\n**(’CONCEPT_Hypercarnivore’, X.classD)**\\n\\n**AS SimScore**\\n\\n**FROM ImageDataTable X WHERE**\\n\\n**…….**\\n\\n**…….**\\n\\n**…….**\\n\\n**( (stringPresent(X.classD, ’scavenger’) == 0) AND**\\n**(proximityAvgForExtKB**\\n**(’CONCEPT_Hypercarnivore’,X.classD) > 0.5)**\\n\\n**ORDER BY SimScore DESC**\\n\\n\\n\\n**Figure** **18:** **Similarity** **query** **over** **images** **using**\\n**a** **model** **trained** **from** **external** **knowledge** **base**\\n**(Wikipedia)**\\n\\n\\nAlthough we used hypothetical scenarios to demonstrate\\nour ideas, CI queries are applicable to a broad class of domains. These include finance, insurance, retail, customer\\ncare, log analytics, healthcare, genomics, semantic search\\nover documents (patent, legal, or financial), healthcare informatics, and human resource management.\\nThese examples demonstrate several unique capabilities\\nof cognitive database systems, namely: (1) ability to build\\njoint cross-modal semantic model from multi-modal data,\\n(2) _transperent_ integration of novel cognitive queries into\\nexisting SQL query infrastructure, (3) using untyped vector representations to support contextual semantic (i.e. not\\nvalue based) queries across multiple SQL data types, and\\n(4) ability to import an externally trained semantic model\\nand apply it to enable querying a database using a token not\\npresent in the database. To the best of our knowledge, none\\nof the current industrial, academic, or open source database\\nsystems support these capabilities.\\n\\n\\n**5.1** **Optimizing Cognitive Intelligence Queries**\\n\\nCognitive Intelligence queries are standard SQL analytics\\nqueries which invoke UDFs to enable contextual semantic\\noperations between relational variables. Irrespective of the\\nkind of CI Query, core UDF computation involves computing pair-wise similarities between vectors, which can be then\\nused to identify nearest or furthest neighbors of a vector. In\\nthe worst case, a CI query can invoke a UDF for every row\\ncombination being evaluated and the UDF, in turn, can operate on a large number of vectors. Since in practice, the\\nnumber of row combinations can very high, it is critical to\\noptimize the performance of distance computations in the\\nnearest-neighbor calculations for CI queries.\\nIn a _d_ dimensional vector space, pair-wise distance between vectors _v_ 1 and _v_ 2 is calculated by computing the cosine distance, _cos_ ( _v_ 1 _, v_ 2 ) = _∥vv_ 11 _∥∥·vv_ 22 _∥_ [. As we use normalized]\\nforms of vectors (i.e. _∥v∥_ = 1), the pair-wise distance calculation gets simplified to a vector dotproduct, _v_ 1 _· v_ 2 . In\\ngeneral, there are four basic ways of optimizing distance\\ncomputations:\\n\\n\\n_•_ Increasing computation granularity: In cases where\\none needs to compute the distance of a vector from\\nmany vectors, many individual dotproduct operations\\n\\n\\n\\n11\\n\\n\\n', 'words': []}\n",
      "\n",
      "{'metadata': {'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref package', 'producer': 'pdfTeX-1.40.17', 'creationDate': 'D:20171221013320Z', 'modDate': 'D:20171221013320Z', 'trapped': '', 'encryption': None, 'file_path': '/Users/ngocduy/Documents/PAPERS/cs_DB/Cognitive Database_ A Step towards Endowing Relational Databases with Artificial Intelligence Capabilities.pdf', 'page_count': 14, 'page': 12}, 'toc_items': [[1, '7 Conclusions and Success Criteria', 12], [2, '7.1 Success Criteria', 12]], 'tables': [], 'images': [], 'graphics': [], 'text': 'even documents. Applications to the paragraph and document embedding appear in [34, 15]. Recent work has also\\nbeen exploring applying word embeddings to capture image\\nsemantics [57].\\n**Applications of Word Embedding:** The word embedding model is being used for a wide variety of applications\\nbeyond NLP. Wu et al [64] provide a general neural framework for building vector embaddings of entities of different types into a vectorial embedding space. The common\\nrepresentation can be then used for different tasks such as\\ntext classification, link prediction, document recommendation, etc. The YouTube recommendation system uses embedding approaches to capture user behavior [13]. Similar embedding-based approaches have been used for recommending news articles [48], for discovering topics [65], or for\\npersonalized fashion shopping [47, 2]. Hope et. al. have proposed using word embedding for supporting analogy queries\\nover knowledge bases such as the US Patent database [29].\\nDeepWalk [52] and Node2Vec [23] have proposed using word\\nembedding approaches for learning neighborhood features\\nof nodes in a network graph. Word embedding approaches\\nare also being used for a variety of semantic web applications, e.g., embedding RDF triples [53, 12] and encoding\\ngeo-spatial proximity [33]. Using latent feature vectors for\\ndata integration in knowledge databases has been explored\\nin [61, 60].\\n**Relational Databases:** In the context of SQL, text capabilities, e.g., the use of synonyms, have been in practice for\\na while [14]. In the literature, techniques for detecting similarity between records and fields have also been explored.\\nSemantic similarity between database records is explored\\nin [32]. Phrase-based ranking by applying an IR approach\\nto relational data appears in [40]. Indexing and searching relational data by modeling tuples as virtual documents\\nappear in [41]. Effective keyword-based selection of relational databases is explored in [66]. A system for detecting\\nXML similarity, in content and structure, using a relational\\ndatabase is described in [62]. Related work on similarity\\nJoin appears in [10]. Semantic Queries are described in [49].\\nMost recently, Shin et al. have described DeepDive [56] that\\nuses machine learning techniques, e.g., Markov Logic based\\nrules, to convert input unstructured documents into a structured knowledge base.\\nThe proposed cognitive database system can be distinguished by the following unique features: (1) Encoding relational data using word embedding techniques, (2) Using semantic vectors to enable a new class of SQL analytics queries\\n(CI queries), (3) Ability to make _contextual semantic_ matching, unlike the traditional _value (syntactical)_ matching supported by current SQL queries, (4) Capturing relationalships\\nacross multiple data types, including images, and (5) Ability of using external knowledge bases. Further, semantic\\nvectors are primarily based on the database _itself_ (with external text or vectors as an option). This means that we assume no reliance on dictionaries, thesauri, word nets and the\\nlike. Once these vectors are generated they may be used in\\nvastly enriching the querying expressiveness of virtually any\\nquery language. These capabilities go far beyond analytical\\ncapabilities present in current relational systems. All wellknown commercial and open source (e.g., Apache Spark [1],\\nMADlib [25]) database systems have built-in analytics capabilities, e.g., Spark MLLib. Apache Spark can also create\\na deep-learning pipeline in which it can invoke an external\\n\\n\\n\\ndeep-learning infrastructure e.g., TensorFlow [21] to train a\\nmodel, and then load the trained model to perform inferencing operations [28]. However, such systems view databases\\nas repositories for storing input features and results for the\\nanalytics or deep-learning frameworks. On the other hand,\\ncognitive databases use the word embedding model to extract features from the database entities and use them to enhance its querying capabilities. Systems based on statistical\\nrelational learning models combine probabilistic graphical\\nmodels and first-order logic to encode uncertain first-order\\nlogic rules based on _known_ information [63]. In contrast, a\\ncognitive database learns information about the relational\\ndata which is not known apriori.\\n\\n\\n**7.** **CONCLUSIONS AND SUCCESS CRITE-**\\n\\n**RIA**\\n\\nIn this paper we presented Cognitive Database, an innovative relational database system that uses the power\\nof word embedding models to enable novel AI capabilities\\nin database systems. The word embedding approach uses\\nunsupervised learning to generate meaning vectors using\\ndatabase-derived text. These vectors capture syntactic as\\nwell as semantic characteristics of every database token. We\\nuse these vectors to enhance database querying capabilities.\\nIn essence, these vectors provide another way to look at\\nthe database, almost orthogonal to the structured relational\\nregime, as vectors enable a dual view of the data: relational\\nand meaningful text. We thereby introduce and explore a\\nnew class of queries called _cognitive intelligence (CI)_ queries\\nthat extract information from the database based, in part,\\non the relationships encoded by these vectors.\\nWe are implementing a prototype system on top of Apache\\nSpark [1] to exhibit the power of CI queries. Our current\\ninfrastructure enables complex SQL-based semantic queries\\nover multi-modal databases (e.g., inductive reasoning queries\\nover a text and image database). We are now working on\\naccelerating model training and nearest neighbor computations using a variety of approaches (e.g., using GPUs),\\nand developing new techniques for incremental vector training. We believe CI queries are applicable to a broad class of\\napplication domains including healthcare, bio-informatics,\\ndocument searching, retail analysis, and data integration.\\n\\n\\n**7.1** **Success Criteria**\\n\\nWe believe Cognitive Databases are truly a new technology for incorporating AI capabilities into relational databases.\\nAs such it holds a great promise for innovative applications\\nwith a very different view of data as compared to today’s\\ndatabase systems. Since it is based on a new concept, there\\nare no easy comparisons. For example, there are no relevant benchmarks except for ones used in NLP for testing\\nlanguage features such as analogies [45]. So, success of the\\ncognitive databases will be mainly evaluated based on new\\napplications within known domains (such as Retail), new\\ndomains of applications (such as medical drugs selection)\\nthat are currently in the sphere of AI-based systems, and\\nthe adaptation of CI capabilities as a standard feature by\\nleading vendor as well as open source database systems. Finally, we hope this work spurs new research initiatives in this\\nexciting emerging area in database management systems.\\n\\n\\n\\n12\\n\\n\\n', 'words': []}\n",
      "\n",
      "{'metadata': {'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref package', 'producer': 'pdfTeX-1.40.17', 'creationDate': 'D:20171221013320Z', 'modDate': 'D:20171221013320Z', 'trapped': '', 'encryption': None, 'file_path': '/Users/ngocduy/Documents/PAPERS/cs_DB/Cognitive Database_ A Step towards Endowing Relational Databases with Artificial Intelligence Capabilities.pdf', 'page_count': 14, 'page': 13}, 'toc_items': [[1, '8 References', 13]], 'tables': [], 'images': [], 'graphics': [], 'text': '**8.** **REFERENCES**\\n\\n[1] Apache Foundation. Apache spark: A fast and general\\nengine for large-scale data processing, 2017. Release\\n2.2.\\n\\n[2] S. Arora and D. Warrier. Decoding fashion contexts\\nusing word embeddings. In _KDD Workshop on_\\n_Machine learning meets fashion_, 2016.\\n\\n[3] D. Bahdanau, K. Cho, and Y. Bengio. Neural machine\\ntranslation by jointly learning to align and translate.\\nIn _Proceedings of the ICLR 2015_, 2015.\\n\\n[4] M. Baroni, G. Dinu, and G. Kruszewski. Dont count,\\npredict! a systematic comparison of context-counting\\nvs. context-predicting semantic vectors. In _Proceedings_\\n_of The 2014 Conference of the Association for_\\n_Computational Linguistics_, 2014.\\n\\n[5] Y. Bengio, R. Ducharme, P. Vincent, and C. Janvin.\\nA neural probabilistic language model. _Journal of_\\n_Machine Learning Research_, 3:1137–1155, 2003.\\n\\n[6] R. Bordawekar, B. Blainey, and R. Puri. _Analyzing_\\n_Analytics_ . Morgan & Claypool Publishers, November\\n2015. Synthesis Lectures on Computer Architecture.\\n\\n[7] R. Bordawekar and P. D’Souza. Optimizing\\nOut-of-core Nearest Neighbor Problems on\\nMulti-GPU Systems using NVLink. Nvidia Global\\nTechnical Conference (GTC), May 2017.\\n\\n[8] R. Bordawekar and O. Shmueli. Enabling cognitive\\nintelligence queries in relational databases using\\nlow-dimensional word embeddings. _CoRR_,\\nabs/1603.07185, March 2016.\\n\\n[9] M. S. Charikar. Similarity estimation techniques from\\nrounding algorithms. In _Proceedings of the_\\n_Thiry-fourth Annual ACM Symposium on Theory of_\\n_Computing_, pages 380–388, 2002.\\n\\n[10] S. Chaudhuri, V. Ganti, and R. Kaushik. A primitive\\noperator for similarity joins in data cleaning. In\\n_Proceedings of the 22nd International Conference on_\\n_Data Engineering_, Washington, DC, USA, 2006. IEEE\\nComputer Society.\\n\\n[11] W. W. Chu, H. Yang, and G. Chow. A cooperative\\ndatabase system (cobase) for query relaxation. In\\n_Proceedings of ARPI 1996_, 1996.\\n\\n[12] M. Cochez, P. Ristoski, S. P. Ponzetto, and\\nH. Paulheim. Global rdf vector space embeddings. In\\n_Proceedings of the 16th International Semantic Web_\\n_Conference_, 2017.\\n\\n[13] P. Covington, J. Adams, and E. Sargin. Deep neural\\nnetworks for youtube recommendations. In\\n_Proceedings of the 10th ACM Conference on_\\n_Recommender Systems_, New York, NY, USA, 2016.\\n\\n[14] R. Cutlip and J. Medicke. _Integrated Solutions with_\\n_DB2_ . IBM Press, 2003.\\n\\n[15] A. M. Dai, C. Olah, and Q. V. Le. Document\\nembedding with paragraph vectors. _CoRR_,\\nabs/1507.07998, 2015.\\n\\n[16] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and\\nL. Fei-Fei. ImageNet: A Large-Scale Hierarchical\\nImage Database. In _CVPR09_, 2009.\\n\\n[17] I. S. Dhillon and D. S. Modha. Concept\\ndecompositions for large sparse text data using\\nclustering. _Mach. Learn._, 42(1-2):143–175, Jan. 2001.\\n\\n[18] M. N. Diascro and N. Brody. Odd-man-out and\\nintelligence. _Intelligence_, 19(1):79–92, July-August\\n\\n\\n\\n1994.\\n\\n[19] Y. Goldberg and O. Levy. word2vec explained:\\nderiving mikolov et al.’s negative-sampling\\nword-embedding method. _CoRR_, abs/1402.3722, 2014.\\n\\n[20] I. Goodfellow, Y. Bengio, and A. Courville. _Deep_\\n_Learning_ . The MIT Press, 2016.\\n\\n[21] Google Inc. TensorFlow: An open-source software\\nlibrary for Machine Intelligence.\\n\\n[22] J. Gray, S. Chaudhuri, A. Bosworth, A. Layman,\\nD. Reichart, M. Venkatrao, F. Pellow, and\\nH. Pirahesh. Data cube: A relational aggregation\\noperator generalizing group-by, cross-tab, and\\nsub-totals. _Data Mining and Knowledge Discovery_,\\n1(1):29–53, 1997.\\n\\n[23] A. Grover and J. Leskovec. Node2vec: Scalable feature\\nlearning for networks. In _Proceedings of the 22nd ACM_\\n_SIGKDD International Conference on Knowledge_\\n_Discovery and Data Mining_, KDD ’16, pages 855–864,\\n2016.\\n\\n[24] Z. S. Harris. Distributional structure. _Word_,\\n10(2-3):146–162, 1954.\\n\\n[25] J. M. Hellerstein, C. Re, F. Schoppmann, D. Z. Wang,\\nE. Fratkin, A. Gorajek, K. S. Ng, C. Welton, X. Feng,\\nK. Li, and A. Kumar. The MADlib analytics library:\\nor MAD skills, the SQL. _Proc. VLDB Endow._, 5(12),\\nAugust 2012.\\n\\n[26] G. E. Hinton. Learning distributed representations of\\nconcepts. In _Proceedings of the Eighth Annual_\\n_Conference of Cognitive Science Society_, pages 1–12,\\n1986.\\n\\n[27] C.-T. Ho, R. Agrawal, N. Megiddo, and R. Srikant.\\nRange queries in olap data cubes. In _Proceedings of_\\n_the 1997 ACM SIGMOD International Conference on_\\n_Management of Data_, pages 73–88, 1997.\\n\\n[28] S. A. Hong, T. Hunter, and R. Xin. A vision for\\nmaking deep learning simple, June 2017. DataBricks\\nEngineering Blog.\\n\\n[29] T. Hope, J. Chan, A. Kittur, and D. Shahaf.\\nAccelerating innovation through analogy mining. In\\n_Proceedings of the 23rd ACM SIGKDD International_\\n_Conference on Knowledge Discovery and Data Mining_,\\nKDD ’17, pages 235–243, 2017.\\n\\n[30] IBM Watson. Watson visual recognition service.\\nwww.ibm.com/watson/services/visual-recognition/.\\n\\n[31] Y. Jia, E. Shelhamer, J. Donahue, S. Karayev,\\nJ. Long, R. Girshick, S. Guadarrama, and T. Darrell.\\nCaffe: Convolutional architecture for fast feature\\nembedding. _arXiv preprint arXiv:1408.5093_, 2014.\\n\\n[32] V. Kashyap and A. P. Sheth. Semantic and schematic\\nsimilarities between database objects: A context-based\\napproach. _VLDB J._, 5(4):276–304, 1996.\\n\\n[33] M. Kejriwal and P. Szekely. Neural embeddings for\\npopulated geonames locations. In _Proceedings of the_\\n_16th International Semantic Web Conference_, 2017.\\n\\n[34] Q. V. Le and T. Mikolov. Distributed representations\\nof sentences and documents. _CoRR_, abs/1405.4053,\\n2014.\\n\\n[35] O. Levy and Y. Goldberg. Linguistic regularities in\\nsparse and explicit word representations. In\\n_Proceedings of the Eighteenth Conference on_\\n_Computational Natural Language Learning, CoNLL_\\n\\n\\n\\n13\\n\\n\\n', 'words': []}\n",
      "\n",
      "{'metadata': {'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref package', 'producer': 'pdfTeX-1.40.17', 'creationDate': 'D:20171221013320Z', 'modDate': 'D:20171221013320Z', 'trapped': '', 'encryption': None, 'file_path': '/Users/ngocduy/Documents/PAPERS/cs_DB/Cognitive Database_ A Step towards Endowing Relational Databases with Artificial Intelligence Capabilities.pdf', 'page_count': 14, 'page': 14}, 'toc_items': [], 'tables': [], 'images': [], 'graphics': [], 'text': '_2014_, pages 171–180, 2014.\\n\\n[36] O. Levy and Y. Goldberg. Neural word embedding as\\nimplicit matrix factorization. In _Annual Conference on_\\n_Neural Information Processing Systems 2014_, pages\\n2177–2185, 2014.\\n\\n[37] F. Li and H. V. Jagadish. Constructing an interactive\\nnatural language interface for relational databases.\\n_Proc. VLDB Endow._, 8(1):73–84, Sept. 2014.\\n\\n[38] L. Lim, H. Wang, and M. Wang. Semantic queries by\\nexample. In _Proceedings of the 16th International_\\n_Conference on Extending Database Technology (EDBT_\\n_2013)_, 2013.\\n\\n[39] T. Linzen. Issues in evaluating semantic spaces using\\nword analogies. _arXiv preprint arXiv:1606.07736_,\\n2016.\\n\\n[40] F. Liu, C. T. Yu, W. Meng, and A. Chowdhury.\\nEffective keyword search in relational databases. In\\n_Proceedings of the ACM SIGMOD International_\\n_Conference on Management of Data, Chicago, Illinois,_\\n_USA, June 27-29, 2006_, pages 563–574, 2006.\\n\\n[41] Y. Luo, X. Lin, W. Wang, and X. Zhou. Spark: top-k\\nkeyword query in relational databases. In _Proceedings_\\n_of the ACM SIGMOD International Conference on_\\n_Management of Data, Beijing, China, June 12-14,_\\n_2007_, pages 115–126, 2007.\\n\\n[42] T. Mikolov. word2vec: Tool for computing continuous\\ndistributed representations of words, 2013.\\ngithub.com/tmikolov/word2vec.\\n\\n[43] T. Mikolov, K. Chen, G. Corrado, and J. Dean.\\nEfficient estimation of word representations in vector\\nspace. _CoRR_, abs/1301.3781, 2013.\\n\\n[44] T. Mikolov, Q. V. Le, and I. Sutskever. Exploiting\\nsimilarities among languages for machine translation.\\n_CoRR_, abs/1309.4168, 2013.\\n\\n[45] T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and\\nJ. Dean. Distributed representations of words and\\nphrases and their compositionality. In _27th Annual_\\n_Conference on Neural Information Processing Systems_\\n_2013._, pages 3111–3119, 2013.\\n\\n[46] A. Mnih and K. Kavukcuoglu. Learning word\\nembeddings efficiently with noise-contrastive\\nestimation. In _27th Annual Conference on Neural_\\n_Information Processing Systems 2013._, pages\\n2265–2273, 2013.\\n\\n[47] C. Moody. A word is worth a thousand vectors. Stitch\\nFix Multithreaded Blog.\\n\\n[48] S. Okura, Y. Tagami, S. Ono, and A. Tajima.\\nEmbedding-based news recommendation for millions\\nof users. In _Proceedings of the 23rd ACM SIGKDD_\\n_International Conference on Knowledge Discovery and_\\n_Data Mining_, KDD ’17, pages 1933–1942, 2017.\\n\\n[49] Z. Pan and J. Heflin. DLDB: extending relational\\ndatabases to support semantic web queries. In _PSSS1_\\n\\n_- Practical and Scalable Semantic Systems_, 2003.\\n\\n[50] Y. Park, A. S. Tajik, M. Cafarella, and B. Mozafari.\\nDatabase learning: Toward a database that becomes\\nsmarter every time. In _Proceedings of the 2017 ACM_\\n_International Conference on Management of Data_,\\npages 587–602, 2017.\\n\\n[51] J. Pennington, R. Socher, and C. D. Manning. GloVe:\\nGlobal vectors for word representation. In _Proceedings_\\n\\n\\n\\n_of the 2014 Conference on Empirical Methods in_\\n_Natural Language Processing_, pages 1532–1543, 2014.\\n\\n[52] B. Perozzi, R. Al-Rfou, and S. Skiena. Deepwalk:\\nOnline learning of social representations. In\\n_Proceedings of the 20th ACM SIGKDD International_\\n_Conference on Knowledge Discovery and Data Mining_,\\nKDD ’14, pages 701–710, 2014.\\n\\n[53] P. Ristoski and H. Paulheim. Rdf2vec: Rdf graph\\nembedding for data mining. In _Proceedings of the 15th_\\n_International Semantic Web Conference_, pages\\n498–514, 2016.\\n\\n[54] D. E. Rumelhart and A. A. Abrahamson. A model for\\nanalogical reasoning. _Cognitive Psychology_, 5(1):1 –\\n28, 1973.\\n\\n[55] G. Salton, A. Wong, and C. S. Yang. A vector space\\nmodel for automatic indexing. _Communications of the_\\n_ACM_, 18(11):613–620, 1975.\\n\\n[56] J. Shin, S. Wu, F. Wang, C. De Sa, C. Zhang, and\\nC. R´e. Incremental knowledge base construction using\\ndeepdive. _Proc. VLDB Endow._, 8(11), July 2015.\\n\\n[57] R. Socher, M. Ganjoo, H. Sridhar, O. Bastani, C. D.\\nManning, and A. Y. Ng. Zero-shot learning through\\ncross-modal transfer. _CoRR_, abs/1301.3666, 2013.\\n\\n[58] R. J. Sternberg and M. K. Gardner. Unities in\\ninductive reasoning. Technical Report Technical rept.\\nno. 18, 1 Jul-30 Sep 79, Yale University, 1979.\\n\\n[59] D. Van Aken, A. Pavlo, G. J. Gordon, and B. Zhang.\\nAutomatic database management system tuning\\nthrough large-scale machine learning. In _Proceedings_\\n_of the 2017 ACM International Conference on_\\n_Management of Data_, pages 1009–1024, 2017.\\n\\n[60] P. Verga, D. Belanger, E. Strubell, B. Roth, and\\nA. McCallum. Multilingual relation extraction using\\ncompositional universal schema. _CoRR_,\\nabs/1511.06396, 2015.\\n\\n[61] L. Vilnis and A. McCallum. Word representations via\\ngaussian embedding. _CoRR_, abs/1412.6623, 2014.\\n\\n[62] W. Viyanon and S. K. Madria. A system for detecting\\nxml similarity in content and structure using\\nrelational database. In _Proceedings of the 18th ACM_\\n_Conference on Information and Knowledge_\\n_Management, CIKM_, pages 1197–1206, 2009.\\n\\n[63] D. Z. Wang, Y. Chen, C. Grant, and K. Li. Efficient\\nin-database analytics with graphical models. _IEEE_\\n_Data Engineering Bulletin_, 2014.\\n\\n[64] L. Wu, A. Fisch, S. Chopra, K. Adams, A. Bordes,\\nand J. Weston. Starspace: Embed all the things!\\n_CoRR_, abs/1709.03856, 2017.\\n\\n[65] G. Xun, Y. Li, J. Gao, and A. Zhang. Collaboratively\\nimproving topic discovery and word embeddings by\\ncoordinating global and local contexts. In _Proceedings_\\n_of the 23rd ACM SIGKDD International Conference_\\n_on Knowledge Discovery and Data Mining_, KDD ’17,\\npages 535–543, 2017.\\n\\n[66] B. Yu, G. Li, K. R. Sollins, and A. K. H. Tung.\\nEffective keyword-based selection of relational\\ndatabases. In _Proceedings of the ACM SIGMOD_\\n_International Conference on Management of Data,_\\n_Beijing, China, June 12-14, 2007_, pages 139–150,\\n2007.\\n\\n\\n\\n14\\n\\n\\n', 'words': []}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "md_text = pymupdf4llm.to_markdown(\n",
    "    pdf_path,\n",
    "    page_chunks=True\n",
    ")\n",
    "for page_chunk in md_text:\n",
    "    print(page_chunk)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4b216db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(321, 0, 600, 495, 8, 'DeviceRGB', '', 'Image16', 'DCTDecode')]\n"
     ]
    }
   ],
   "source": [
    "pdf = pymupdf.open(pdf_path)\n",
    "page = 8\n",
    "image_list = pdf[page].get_images()\n",
    "print(image_list)\n",
    "for idx, img in enumerate(image_list, start=1):\n",
    "    data = pdf.extract_image(img[0])\n",
    "    with PIL.Image.open(io.BytesIO(data.get('image'))) as image:\n",
    "        image.save(f'{page}-{idx}.{data.get(\"ext\")}', mode='wb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ca5bfb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Picture ID', 'National Park', 'Country', 'Image Path'], ['PK_01', 'Corbett', 'India', 'Img_01.JPEG'], ['PK_05', 'Kruger', 'South Africa', 'Img_05.JPEG'], ['PK_09', 'Sunderbans', 'India', 'Img_09.JPEG'], ['PK_11', 'Serengeti', 'Tanzania', 'Img_11.JPEG']]\n",
      "[['Picture ID', 'Image Path', 'National Park', 'Country', 'Animal Name', 'Class', 'Dietary Habit', 'color'], ['PK_01', 'Img_01.JPEG', 'Corbett', 'India', 'Tiger', 'Mammal', 'Carnivorous', 'Yellow'], ['PK_05', 'Img_05.JPEG', 'Kruger', 'South Africa', 'Rhinoceros', 'Mammal', 'Herbivores', 'Gray'], ['PK_09', 'Img_08.JPEG', 'Sunderbans', 'India', 'Indian Gharial', 'Reptile', 'Carnivorous', 'Gray'], ['PK_11', 'Img_11.JPEG', 'Serengeti', 'Tanzania', 'Crocodile', 'Reptile', 'Carnivorous', 'Gray']]\n"
     ]
    }
   ],
   "source": [
    "tables = pdf[page].find_tables()\n",
    "for table in tables:\n",
    "    print(table.extract())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "backend (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
